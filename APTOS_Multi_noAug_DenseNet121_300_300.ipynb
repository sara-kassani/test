{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 4661051424629016649, name: \"/device:XLA_CPU:0\"\n device_type: \"XLA_CPU\"\n memory_limit: 17179869184\n locality {\n }\n incarnation: 199176327669285678\n physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n device_type: \"XLA_GPU\"\n memory_limit: 17179869184\n locality {\n }\n incarnation: 10669279364384499725\n physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n device_type: \"GPU\"\n memory_limit: 15882446439\n locality {\n   bus_id: 1\n   links {\n   }\n }\n incarnation: 18032932726806003114\n physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\nfrom sklearn.metrics import log_loss\nimport sys\nimport time\nimport math\nimport os\nimport pandas as pd\nfrom keras.callbacks import EarlyStopping\nimport numpy as np\nfrom glob import glob\nimport cv2\nimport skimage\nfrom skimage.transform import resize\nfrom keras.utils.np_utils import to_categorical\nimport keras\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.models import load_model\n# import keras.callbacks as kcall\nfrom keras.optimizers import Adam, RMSprop,SGD\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\nfrom keras.applications.vgg19 import VGG19\nfrom keras.regularizers import l2, l1\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\n\nimport matplotlib.pyplot as plt\nfrom keras.layers import Input, concatenate\nfrom keras import optimizers, metrics, models\nfrom keras.layers import Input, Flatten, Dense\n\n%matplotlib inline","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow as tf\n\nprint(\"Keras Version\", keras.__version__)\nprint(\"tensorflow Version\", tf.__version__)\n# print(\"dim_ordering:\", K.image_dim_ordering())","execution_count":4,"outputs":[{"output_type":"stream","text":"Keras Version 2.2.4\ntensorflow Version 1.14.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nimg_height, img_width = 450, 450\ninput_shape = (img_height, img_width, 3)\nepochs = 1000","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/aptos-multiclass-noaug/aptos_multiclass/\"))","execution_count":6,"outputs":[{"output_type":"stream","text":"['test', 'train']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/aptos-multiclass-noaug/aptos_multiclass/train/'\ntest_dir = '../input/aptos-multiclass-noaug/aptos_multiclass/test/'","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_input(x):\n    # 'RGB'->'BGR'\n    x = x[:, :, ::-1]\n    # Zero-center by imagenet mean pixel\n    x[:, :, 0] -= 103.939\n    x[:, :, 1] -= 116.779\n    x[:, :, 2] -= 123.68\n    return x","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed = np.random.seed(1142)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n#     featurewise_center=True,\n#     featurewise_std_normalization=True,\n    preprocessing_function = preprocess_input,\n    validation_split= 0.3)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    subset = 'training',\n    class_mode='categorical')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    subset = 'validation',\n    class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function = preprocess_input)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    class_mode='categorical')","execution_count":9,"outputs":[{"output_type":"stream","text":"Found 2325 images belonging to 5 classes.\nFound 994 images belonging to 5 classes.\nFound 343 images belonging to 5 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_train_samples = len(train_generator.filenames)\nnb_validation_samples = len(validation_generator.filenames)\nnb_test_samples = len(test_generator.filenames)\n\npredict_size_train = int(math.ceil(nb_train_samples / batch_size))\npredict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\npredict_size_test = int(math.ceil(nb_test_samples / batch_size))\n\nnum_classes = len(train_generator.class_indices)\n\nprint(\"nb_train_samples:\", nb_train_samples)\nprint(\"nb_validation_samples:\", nb_validation_samples)\nprint(\"nb_test_samples:\", nb_test_samples)\n\nprint(\"\\npredict_size_train:\", predict_size_train)\nprint(\"predict_size_validation:\", predict_size_validation)\nprint(\"predict_size_test:\", predict_size_test)\n\nprint(\"\\n num_classes:\", num_classes)","execution_count":10,"outputs":[{"output_type":"stream","text":"nb_train_samples: 2325\nnb_validation_samples: 994\nnb_test_samples: 343\n\npredict_size_train: 37\npredict_size_validation: 16\npredict_size_test: 6\n\n num_classes: 5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"extracted_features\")\nextracted_features_dir = \"extracted_features/\"\nmodel_name = \"MobileNet_descriptors\"","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg19_weights =\"../input/full-keras-pretrained-no-top/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ninception_weights =\"../input/full-keras-pretrained-no-top//inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nvgg16_weights =\"../input/full-keras-pretrained-no-top/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ndenseNet201_weights =\"../input/full-keras-pretrained-no-top/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ndenseNet121_weights =\"../input/full-keras-pretrained-no-top/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nresenet50_weights =\"../input/full-keras-pretrained-no-top/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ninception_resnet_v2_weights =\"../input/full-keras-pretrained-no-top/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nnasnet_weights =\"../input/full-keras-pretrained-no-top/nasnet_large_no_top.h5\"\nnasnet_mobile_weights =\"../input/full-keras-pretrained-no-top/nasnet_mobile_no_top.h5\"\nmobilenet_weights =\"../input/full-keras-pretrained-no-top/mobilenet_1_0_224_tf_no_top.h5\"\nxception_weights = \"../input/full-keras-pretrained-no-top/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.applications import DenseNet201\nfrom keras.applications import DenseNet121\nfrom keras.applications import ResNet50\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications import NASNetLarge, NASNetMobile\nfrom keras.applications import MobileNet","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor = Input(shape = input_shape)  \n\nbase_model1=DenseNet121(weights=denseNet121_weights, include_top=False, pooling = \"avg\")\n# base_model2=Xception(input_shape= input_shape,weights=xception_weights, include_top=False, input_tensor=input_tensor)\n\n# x1 = base_model1.output\n# x1 = GlobalAveragePooling2D()(x1)\n\n# x2 = base_model2.output\n# x2 = GlobalAveragePooling2D()(x2)\n\n# merge = concatenate([x1, x2])\n# predictions = Dense(num_classes, activation='softmax')(merge)\n\n# model = Model(inputs=input_tensor,outputs=predictions)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model1.summary()","execution_count":15,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, None, None, 3 0                                            \n__________________________________________________________________________________________________\nzero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           input_2[0][0]                    \n__________________________________________________________________________________________________\nconv1/conv (Conv2D)             (None, None, None, 6 9408        zero_padding2d_1[0][0]           \n__________________________________________________________________________________________________\nconv1/bn (BatchNormalization)   (None, None, None, 6 256         conv1/conv[0][0]                 \n__________________________________________________________________________________________________\nconv1/relu (Activation)         (None, None, None, 6 0           conv1/bn[0][0]                   \n__________________________________________________________________________________________________\nzero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           conv1/relu[0][0]                 \n__________________________________________________________________________________________________\npool1 (MaxPooling2D)            (None, None, None, 6 0           zero_padding2d_2[0][0]           \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, None, None, 6 256         pool1[0][0]                      \n__________________________________________________________________________________________________\nconv2_block1_0_relu (Activation (None, None, None, 6 0           conv2_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, None, None, 1 8192        conv2_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, None, None, 1 512         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, None, None, 1 0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_concat (Concatenat (None, None, None, 9 0           pool1[0][0]                      \n                                                                 conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_0_bn (BatchNormali (None, None, None, 9 384         conv2_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_0_relu (Activation (None, None, None, 9 0           conv2_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, None, None, 1 12288       conv2_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, None, None, 1 512         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, None, None, 1 0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_concat (Concatenat (None, None, None, 1 0           conv2_block1_concat[0][0]        \n                                                                 conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_0_bn (BatchNormali (None, None, None, 1 512         conv2_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_0_relu (Activation (None, None, None, 1 0           conv2_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, None, None, 1 16384       conv2_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, None, None, 1 512         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, None, None, 1 0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_concat (Concatenat (None, None, None, 1 0           conv2_block2_concat[0][0]        \n                                                                 conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_0_bn (BatchNormali (None, None, None, 1 640         conv2_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_0_relu (Activation (None, None, None, 1 0           conv2_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block4_1_conv (Conv2D)    (None, None, None, 1 20480       conv2_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_1_bn (BatchNormali (None, None, None, 1 512         conv2_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_1_relu (Activation (None, None, None, 1 0           conv2_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_concat (Concatenat (None, None, None, 1 0           conv2_block3_concat[0][0]        \n                                                                 conv2_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_0_bn (BatchNormali (None, None, None, 1 768         conv2_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_0_relu (Activation (None, None, None, 1 0           conv2_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block5_1_conv (Conv2D)    (None, None, None, 1 24576       conv2_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_1_bn (BatchNormali (None, None, None, 1 512         conv2_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_1_relu (Activation (None, None, None, 1 0           conv2_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_concat (Concatenat (None, None, None, 2 0           conv2_block4_concat[0][0]        \n                                                                 conv2_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_0_bn (BatchNormali (None, None, None, 2 896         conv2_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_0_relu (Activation (None, None, None, 2 0           conv2_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block6_1_conv (Conv2D)    (None, None, None, 1 28672       conv2_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_1_bn (BatchNormali (None, None, None, 1 512         conv2_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_1_relu (Activation (None, None, None, 1 0           conv2_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv2_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_concat (Concatenat (None, None, None, 2 0           conv2_block5_concat[0][0]        \n                                                                 conv2_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\npool2_bn (BatchNormalization)   (None, None, None, 2 1024        conv2_block6_concat[0][0]        \n__________________________________________________________________________________________________\npool2_relu (Activation)         (None, None, None, 2 0           pool2_bn[0][0]                   \n__________________________________________________________________________________________________\npool2_conv (Conv2D)             (None, None, None, 1 32768       pool2_relu[0][0]                 \n__________________________________________________________________________________________________\npool2_pool (AveragePooling2D)   (None, None, None, 1 0           pool2_conv[0][0]                 \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, None, None, 1 512         pool2_pool[0][0]                 \n__________________________________________________________________________________________________\nconv3_block1_0_relu (Activation (None, None, None, 1 0           conv3_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, None, None, 1 16384       conv3_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_concat (Concatenat (None, None, None, 1 0           pool2_pool[0][0]                 \n                                                                 conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_0_bn (BatchNormali (None, None, None, 1 640         conv3_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_0_relu (Activation (None, None, None, 1 0           conv3_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, None, None, 1 20480       conv3_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_concat (Concatenat (None, None, None, 1 0           conv3_block1_concat[0][0]        \n                                                                 conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_0_bn (BatchNormali (None, None, None, 1 768         conv3_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_0_relu (Activation (None, None, None, 1 0           conv3_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, None, None, 1 24576       conv3_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_concat (Concatenat (None, None, None, 2 0           conv3_block2_concat[0][0]        \n                                                                 conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_0_bn (BatchNormali (None, None, None, 2 896         conv3_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_0_relu (Activation (None, None, None, 2 0           conv3_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, None, None, 1 28672       conv3_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_concat (Concatenat (None, None, None, 2 0           conv3_block3_concat[0][0]        \n                                                                 conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_0_bn (BatchNormali (None, None, None, 2 1024        conv3_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_0_relu (Activation (None, None, None, 2 0           conv3_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_1_conv (Conv2D)    (None, None, None, 1 32768       conv3_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_bn (BatchNormali (None, None, None, 1 512         conv3_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_relu (Activation (None, None, None, 1 0           conv3_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_concat (Concatenat (None, None, None, 2 0           conv3_block4_concat[0][0]        \n                                                                 conv3_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_0_bn (BatchNormali (None, None, None, 2 1152        conv3_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_0_relu (Activation (None, None, None, 2 0           conv3_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_1_conv (Conv2D)    (None, None, None, 1 36864       conv3_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_bn (BatchNormali (None, None, None, 1 512         conv3_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_relu (Activation (None, None, None, 1 0           conv3_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_concat (Concatenat (None, None, None, 3 0           conv3_block5_concat[0][0]        \n                                                                 conv3_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_0_bn (BatchNormali (None, None, None, 3 1280        conv3_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_0_relu (Activation (None, None, None, 3 0           conv3_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_1_conv (Conv2D)    (None, None, None, 1 40960       conv3_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_bn (BatchNormali (None, None, None, 1 512         conv3_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_relu (Activation (None, None, None, 1 0           conv3_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_concat (Concatenat (None, None, None, 3 0           conv3_block6_concat[0][0]        \n                                                                 conv3_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_0_bn (BatchNormali (None, None, None, 3 1408        conv3_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_0_relu (Activation (None, None, None, 3 0           conv3_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_1_conv (Conv2D)    (None, None, None, 1 45056       conv3_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_bn (BatchNormali (None, None, None, 1 512         conv3_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_relu (Activation (None, None, None, 1 0           conv3_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_concat (Concatenat (None, None, None, 3 0           conv3_block7_concat[0][0]        \n                                                                 conv3_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_0_bn (BatchNormali (None, None, None, 3 1536        conv3_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_0_relu (Activation (None, None, None, 3 0           conv3_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block9_1_conv (Conv2D)    (None, None, None, 1 49152       conv3_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_1_bn (BatchNormali (None, None, None, 1 512         conv3_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_1_relu (Activation (None, None, None, 1 0           conv3_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv3_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_concat (Concatenat (None, None, None, 4 0           conv3_block8_concat[0][0]        \n                                                                 conv3_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block10_0_bn (BatchNormal (None, None, None, 4 1664        conv3_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block10_0_relu (Activatio (None, None, None, 4 0           conv3_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block10_1_conv (Conv2D)   (None, None, None, 1 53248       conv3_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_1_bn (BatchNormal (None, None, None, 1 512         conv3_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_1_relu (Activatio (None, None, None, 1 0           conv3_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_concat (Concatena (None, None, None, 4 0           conv3_block9_concat[0][0]        \n                                                                 conv3_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_0_bn (BatchNormal (None, None, None, 4 1792        conv3_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_0_relu (Activatio (None, None, None, 4 0           conv3_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block11_1_conv (Conv2D)   (None, None, None, 1 57344       conv3_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_1_bn (BatchNormal (None, None, None, 1 512         conv3_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_1_relu (Activatio (None, None, None, 1 0           conv3_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_concat (Concatena (None, None, None, 4 0           conv3_block10_concat[0][0]       \n                                                                 conv3_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_0_bn (BatchNormal (None, None, None, 4 1920        conv3_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_0_relu (Activatio (None, None, None, 4 0           conv3_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block12_1_conv (Conv2D)   (None, None, None, 1 61440       conv3_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_1_bn (BatchNormal (None, None, None, 1 512         conv3_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_1_relu (Activatio (None, None, None, 1 0           conv3_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv3_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_concat (Concatena (None, None, None, 5 0           conv3_block11_concat[0][0]       \n                                                                 conv3_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\npool3_bn (BatchNormalization)   (None, None, None, 5 2048        conv3_block12_concat[0][0]       \n__________________________________________________________________________________________________\npool3_relu (Activation)         (None, None, None, 5 0           pool3_bn[0][0]                   \n__________________________________________________________________________________________________\npool3_conv (Conv2D)             (None, None, None, 2 131072      pool3_relu[0][0]                 \n__________________________________________________________________________________________________\npool3_pool (AveragePooling2D)   (None, None, None, 2 0           pool3_conv[0][0]                 \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, None, None, 2 1024        pool3_pool[0][0]                 \n__________________________________________________________________________________________________\nconv4_block1_0_relu (Activation (None, None, None, 2 0           conv4_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, None, None, 1 32768       conv4_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, None, None, 1 512         conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, None, None, 1 0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_concat (Concatenat (None, None, None, 2 0           pool3_pool[0][0]                 \n                                                                 conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_0_bn (BatchNormali (None, None, None, 2 1152        conv4_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_0_relu (Activation (None, None, None, 2 0           conv4_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, None, None, 1 36864       conv4_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, None, None, 1 512         conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, None, None, 1 0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_concat (Concatenat (None, None, None, 3 0           conv4_block1_concat[0][0]        \n                                                                 conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_0_bn (BatchNormali (None, None, None, 3 1280        conv4_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_0_relu (Activation (None, None, None, 3 0           conv4_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, None, None, 1 40960       conv4_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, None, None, 1 512         conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, None, None, 1 0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_concat (Concatenat (None, None, None, 3 0           conv4_block2_concat[0][0]        \n                                                                 conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_0_bn (BatchNormali (None, None, None, 3 1408        conv4_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_0_relu (Activation (None, None, None, 3 0           conv4_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, None, None, 1 45056       conv4_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, None, None, 1 512         conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, None, None, 1 0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_concat (Concatenat (None, None, None, 3 0           conv4_block3_concat[0][0]        \n                                                                 conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_0_bn (BatchNormali (None, None, None, 3 1536        conv4_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_0_relu (Activation (None, None, None, 3 0           conv4_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, None, None, 1 49152       conv4_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, None, None, 1 512         conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, None, None, 1 0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_concat (Concatenat (None, None, None, 4 0           conv4_block4_concat[0][0]        \n                                                                 conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_0_bn (BatchNormali (None, None, None, 4 1664        conv4_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_0_relu (Activation (None, None, None, 4 0           conv4_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, None, None, 1 53248       conv4_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, None, None, 1 512         conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, None, None, 1 0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_concat (Concatenat (None, None, None, 4 0           conv4_block5_concat[0][0]        \n                                                                 conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_0_bn (BatchNormali (None, None, None, 4 1792        conv4_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_0_relu (Activation (None, None, None, 4 0           conv4_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_1_conv (Conv2D)    (None, None, None, 1 57344       conv4_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_bn (BatchNormali (None, None, None, 1 512         conv4_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_relu (Activation (None, None, None, 1 0           conv4_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_concat (Concatenat (None, None, None, 4 0           conv4_block6_concat[0][0]        \n                                                                 conv4_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_0_bn (BatchNormali (None, None, None, 4 1920        conv4_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_0_relu (Activation (None, None, None, 4 0           conv4_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_1_conv (Conv2D)    (None, None, None, 1 61440       conv4_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_bn (BatchNormali (None, None, None, 1 512         conv4_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_relu (Activation (None, None, None, 1 0           conv4_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_concat (Concatenat (None, None, None, 5 0           conv4_block7_concat[0][0]        \n                                                                 conv4_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_0_bn (BatchNormali (None, None, None, 5 2048        conv4_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_0_relu (Activation (None, None, None, 5 0           conv4_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_1_conv (Conv2D)    (None, None, None, 1 65536       conv4_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_bn (BatchNormali (None, None, None, 1 512         conv4_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_relu (Activation (None, None, None, 1 0           conv4_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv4_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_concat (Concatenat (None, None, None, 5 0           conv4_block8_concat[0][0]        \n                                                                 conv4_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_0_bn (BatchNormal (None, None, None, 5 2176        conv4_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_0_relu (Activatio (None, None, None, 5 0           conv4_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_1_conv (Conv2D)   (None, None, None, 1 69632       conv4_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_bn (BatchNormal (None, None, None, 1 512         conv4_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_relu (Activatio (None, None, None, 1 0           conv4_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_concat (Concatena (None, None, None, 5 0           conv4_block9_concat[0][0]        \n                                                                 conv4_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_0_bn (BatchNormal (None, None, None, 5 2304        conv4_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_0_relu (Activatio (None, None, None, 5 0           conv4_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_1_conv (Conv2D)   (None, None, None, 1 73728       conv4_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_bn (BatchNormal (None, None, None, 1 512         conv4_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_relu (Activatio (None, None, None, 1 0           conv4_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_concat (Concatena (None, None, None, 6 0           conv4_block10_concat[0][0]       \n                                                                 conv4_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_0_bn (BatchNormal (None, None, None, 6 2432        conv4_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_0_relu (Activatio (None, None, None, 6 0           conv4_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_1_conv (Conv2D)   (None, None, None, 1 77824       conv4_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_bn (BatchNormal (None, None, None, 1 512         conv4_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_relu (Activatio (None, None, None, 1 0           conv4_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_concat (Concatena (None, None, None, 6 0           conv4_block11_concat[0][0]       \n                                                                 conv4_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_0_bn (BatchNormal (None, None, None, 6 2560        conv4_block12_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_0_relu (Activatio (None, None, None, 6 0           conv4_block13_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_1_conv (Conv2D)   (None, None, None, 1 81920       conv4_block13_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_bn (BatchNormal (None, None, None, 1 512         conv4_block13_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_relu (Activatio (None, None, None, 1 0           conv4_block13_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block13_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_concat (Concatena (None, None, None, 6 0           conv4_block12_concat[0][0]       \n                                                                 conv4_block13_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_0_bn (BatchNormal (None, None, None, 6 2688        conv4_block13_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_0_relu (Activatio (None, None, None, 6 0           conv4_block14_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_1_conv (Conv2D)   (None, None, None, 1 86016       conv4_block14_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_bn (BatchNormal (None, None, None, 1 512         conv4_block14_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_relu (Activatio (None, None, None, 1 0           conv4_block14_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block14_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_concat (Concatena (None, None, None, 7 0           conv4_block13_concat[0][0]       \n                                                                 conv4_block14_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_0_bn (BatchNormal (None, None, None, 7 2816        conv4_block14_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_0_relu (Activatio (None, None, None, 7 0           conv4_block15_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_1_conv (Conv2D)   (None, None, None, 1 90112       conv4_block15_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_bn (BatchNormal (None, None, None, 1 512         conv4_block15_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_relu (Activatio (None, None, None, 1 0           conv4_block15_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block15_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_concat (Concatena (None, None, None, 7 0           conv4_block14_concat[0][0]       \n                                                                 conv4_block15_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_0_bn (BatchNormal (None, None, None, 7 2944        conv4_block15_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_0_relu (Activatio (None, None, None, 7 0           conv4_block16_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_1_conv (Conv2D)   (None, None, None, 1 94208       conv4_block16_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_bn (BatchNormal (None, None, None, 1 512         conv4_block16_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_relu (Activatio (None, None, None, 1 0           conv4_block16_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block16_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_concat (Concatena (None, None, None, 7 0           conv4_block15_concat[0][0]       \n                                                                 conv4_block16_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_0_bn (BatchNormal (None, None, None, 7 3072        conv4_block16_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_0_relu (Activatio (None, None, None, 7 0           conv4_block17_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_1_conv (Conv2D)   (None, None, None, 1 98304       conv4_block17_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_bn (BatchNormal (None, None, None, 1 512         conv4_block17_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_relu (Activatio (None, None, None, 1 0           conv4_block17_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block17_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_concat (Concatena (None, None, None, 8 0           conv4_block16_concat[0][0]       \n                                                                 conv4_block17_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_0_bn (BatchNormal (None, None, None, 8 3200        conv4_block17_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_0_relu (Activatio (None, None, None, 8 0           conv4_block18_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_1_conv (Conv2D)   (None, None, None, 1 102400      conv4_block18_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_bn (BatchNormal (None, None, None, 1 512         conv4_block18_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_relu (Activatio (None, None, None, 1 0           conv4_block18_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block18_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_concat (Concatena (None, None, None, 8 0           conv4_block17_concat[0][0]       \n                                                                 conv4_block18_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_0_bn (BatchNormal (None, None, None, 8 3328        conv4_block18_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_0_relu (Activatio (None, None, None, 8 0           conv4_block19_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_1_conv (Conv2D)   (None, None, None, 1 106496      conv4_block19_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_bn (BatchNormal (None, None, None, 1 512         conv4_block19_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_relu (Activatio (None, None, None, 1 0           conv4_block19_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block19_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_concat (Concatena (None, None, None, 8 0           conv4_block18_concat[0][0]       \n                                                                 conv4_block19_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_0_bn (BatchNormal (None, None, None, 8 3456        conv4_block19_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_0_relu (Activatio (None, None, None, 8 0           conv4_block20_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_1_conv (Conv2D)   (None, None, None, 1 110592      conv4_block20_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_bn (BatchNormal (None, None, None, 1 512         conv4_block20_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_relu (Activatio (None, None, None, 1 0           conv4_block20_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block20_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_concat (Concatena (None, None, None, 8 0           conv4_block19_concat[0][0]       \n                                                                 conv4_block20_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_0_bn (BatchNormal (None, None, None, 8 3584        conv4_block20_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_0_relu (Activatio (None, None, None, 8 0           conv4_block21_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_1_conv (Conv2D)   (None, None, None, 1 114688      conv4_block21_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_bn (BatchNormal (None, None, None, 1 512         conv4_block21_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_relu (Activatio (None, None, None, 1 0           conv4_block21_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block21_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_concat (Concatena (None, None, None, 9 0           conv4_block20_concat[0][0]       \n                                                                 conv4_block21_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_0_bn (BatchNormal (None, None, None, 9 3712        conv4_block21_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_0_relu (Activatio (None, None, None, 9 0           conv4_block22_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_1_conv (Conv2D)   (None, None, None, 1 118784      conv4_block22_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_bn (BatchNormal (None, None, None, 1 512         conv4_block22_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_relu (Activatio (None, None, None, 1 0           conv4_block22_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block22_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_concat (Concatena (None, None, None, 9 0           conv4_block21_concat[0][0]       \n                                                                 conv4_block22_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_0_bn (BatchNormal (None, None, None, 9 3840        conv4_block22_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_0_relu (Activatio (None, None, None, 9 0           conv4_block23_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_1_conv (Conv2D)   (None, None, None, 1 122880      conv4_block23_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_bn (BatchNormal (None, None, None, 1 512         conv4_block23_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_relu (Activatio (None, None, None, 1 0           conv4_block23_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block23_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_concat (Concatena (None, None, None, 9 0           conv4_block22_concat[0][0]       \n                                                                 conv4_block23_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_0_bn (BatchNormal (None, None, None, 9 3968        conv4_block23_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_0_relu (Activatio (None, None, None, 9 0           conv4_block24_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_1_conv (Conv2D)   (None, None, None, 1 126976      conv4_block24_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_bn (BatchNormal (None, None, None, 1 512         conv4_block24_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_relu (Activatio (None, None, None, 1 0           conv4_block24_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_2_conv (Conv2D)   (None, None, None, 3 36864       conv4_block24_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_concat (Concatena (None, None, None, 1 0           conv4_block23_concat[0][0]       \n                                                                 conv4_block24_2_conv[0][0]       \n__________________________________________________________________________________________________\npool4_bn (BatchNormalization)   (None, None, None, 1 4096        conv4_block24_concat[0][0]       \n__________________________________________________________________________________________________\npool4_relu (Activation)         (None, None, None, 1 0           pool4_bn[0][0]                   \n__________________________________________________________________________________________________\npool4_conv (Conv2D)             (None, None, None, 5 524288      pool4_relu[0][0]                 \n__________________________________________________________________________________________________\npool4_pool (AveragePooling2D)   (None, None, None, 5 0           pool4_conv[0][0]                 \n__________________________________________________________________________________________________\nconv5_block1_0_bn (BatchNormali (None, None, None, 5 2048        pool4_pool[0][0]                 \n__________________________________________________________________________________________________\nconv5_block1_0_relu (Activation (None, None, None, 5 0           conv5_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, None, None, 1 65536       conv5_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, None, None, 1 512         conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, None, None, 1 0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_concat (Concatenat (None, None, None, 5 0           pool4_pool[0][0]                 \n                                                                 conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_0_bn (BatchNormali (None, None, None, 5 2176        conv5_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_0_relu (Activation (None, None, None, 5 0           conv5_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, None, None, 1 69632       conv5_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, None, None, 1 512         conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, None, None, 1 0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_concat (Concatenat (None, None, None, 5 0           conv5_block1_concat[0][0]        \n                                                                 conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_0_bn (BatchNormali (None, None, None, 5 2304        conv5_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_0_relu (Activation (None, None, None, 5 0           conv5_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, None, None, 1 73728       conv5_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, None, None, 1 512         conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, None, None, 1 0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_concat (Concatenat (None, None, None, 6 0           conv5_block2_concat[0][0]        \n                                                                 conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_0_bn (BatchNormali (None, None, None, 6 2432        conv5_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_0_relu (Activation (None, None, None, 6 0           conv5_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block4_1_conv (Conv2D)    (None, None, None, 1 77824       conv5_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_1_bn (BatchNormali (None, None, None, 1 512         conv5_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_1_relu (Activation (None, None, None, 1 0           conv5_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block4_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_concat (Concatenat (None, None, None, 6 0           conv5_block3_concat[0][0]        \n                                                                 conv5_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_0_bn (BatchNormali (None, None, None, 6 2560        conv5_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_0_relu (Activation (None, None, None, 6 0           conv5_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block5_1_conv (Conv2D)    (None, None, None, 1 81920       conv5_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_1_bn (BatchNormali (None, None, None, 1 512         conv5_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_1_relu (Activation (None, None, None, 1 0           conv5_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block5_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_concat (Concatenat (None, None, None, 6 0           conv5_block4_concat[0][0]        \n                                                                 conv5_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_0_bn (BatchNormali (None, None, None, 6 2688        conv5_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_0_relu (Activation (None, None, None, 6 0           conv5_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block6_1_conv (Conv2D)    (None, None, None, 1 86016       conv5_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_1_bn (BatchNormali (None, None, None, 1 512         conv5_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_1_relu (Activation (None, None, None, 1 0           conv5_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block6_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_concat (Concatenat (None, None, None, 7 0           conv5_block5_concat[0][0]        \n                                                                 conv5_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_0_bn (BatchNormali (None, None, None, 7 2816        conv5_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_0_relu (Activation (None, None, None, 7 0           conv5_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block7_1_conv (Conv2D)    (None, None, None, 1 90112       conv5_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_1_bn (BatchNormali (None, None, None, 1 512         conv5_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_1_relu (Activation (None, None, None, 1 0           conv5_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block7_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_concat (Concatenat (None, None, None, 7 0           conv5_block6_concat[0][0]        \n                                                                 conv5_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_0_bn (BatchNormali (None, None, None, 7 2944        conv5_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_0_relu (Activation (None, None, None, 7 0           conv5_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block8_1_conv (Conv2D)    (None, None, None, 1 94208       conv5_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_1_bn (BatchNormali (None, None, None, 1 512         conv5_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_1_relu (Activation (None, None, None, 1 0           conv5_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block8_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_concat (Concatenat (None, None, None, 7 0           conv5_block7_concat[0][0]        \n                                                                 conv5_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_0_bn (BatchNormali (None, None, None, 7 3072        conv5_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_0_relu (Activation (None, None, None, 7 0           conv5_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block9_1_conv (Conv2D)    (None, None, None, 1 98304       conv5_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_1_bn (BatchNormali (None, None, None, 1 512         conv5_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_1_relu (Activation (None, None, None, 1 0           conv5_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block9_2_conv (Conv2D)    (None, None, None, 3 36864       conv5_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_concat (Concatenat (None, None, None, 8 0           conv5_block8_concat[0][0]        \n                                                                 conv5_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block10_0_bn (BatchNormal (None, None, None, 8 3200        conv5_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block10_0_relu (Activatio (None, None, None, 8 0           conv5_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block10_1_conv (Conv2D)   (None, None, None, 1 102400      conv5_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block10_1_bn (BatchNormal (None, None, None, 1 512         conv5_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block10_1_relu (Activatio (None, None, None, 1 0           conv5_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block10_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block10_concat (Concatena (None, None, None, 8 0           conv5_block9_concat[0][0]        \n                                                                 conv5_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_0_bn (BatchNormal (None, None, None, 8 3328        conv5_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_0_relu (Activatio (None, None, None, 8 0           conv5_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block11_1_conv (Conv2D)   (None, None, None, 1 106496      conv5_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_1_bn (BatchNormal (None, None, None, 1 512         conv5_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_1_relu (Activatio (None, None, None, 1 0           conv5_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block11_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_concat (Concatena (None, None, None, 8 0           conv5_block10_concat[0][0]       \n                                                                 conv5_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_0_bn (BatchNormal (None, None, None, 8 3456        conv5_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_0_relu (Activatio (None, None, None, 8 0           conv5_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block12_1_conv (Conv2D)   (None, None, None, 1 110592      conv5_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_1_bn (BatchNormal (None, None, None, 1 512         conv5_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_1_relu (Activatio (None, None, None, 1 0           conv5_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block12_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_concat (Concatena (None, None, None, 8 0           conv5_block11_concat[0][0]       \n                                                                 conv5_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_0_bn (BatchNormal (None, None, None, 8 3584        conv5_block12_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_0_relu (Activatio (None, None, None, 8 0           conv5_block13_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block13_1_conv (Conv2D)   (None, None, None, 1 114688      conv5_block13_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_1_bn (BatchNormal (None, None, None, 1 512         conv5_block13_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_1_relu (Activatio (None, None, None, 1 0           conv5_block13_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block13_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block13_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_concat (Concatena (None, None, None, 9 0           conv5_block12_concat[0][0]       \n                                                                 conv5_block13_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_0_bn (BatchNormal (None, None, None, 9 3712        conv5_block13_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_0_relu (Activatio (None, None, None, 9 0           conv5_block14_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block14_1_conv (Conv2D)   (None, None, None, 1 118784      conv5_block14_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_1_bn (BatchNormal (None, None, None, 1 512         conv5_block14_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_1_relu (Activatio (None, None, None, 1 0           conv5_block14_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block14_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block14_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_concat (Concatena (None, None, None, 9 0           conv5_block13_concat[0][0]       \n                                                                 conv5_block14_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_0_bn (BatchNormal (None, None, None, 9 3840        conv5_block14_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_0_relu (Activatio (None, None, None, 9 0           conv5_block15_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block15_1_conv (Conv2D)   (None, None, None, 1 122880      conv5_block15_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_1_bn (BatchNormal (None, None, None, 1 512         conv5_block15_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_1_relu (Activatio (None, None, None, 1 0           conv5_block15_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block15_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block15_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_concat (Concatena (None, None, None, 9 0           conv5_block14_concat[0][0]       \n                                                                 conv5_block15_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_0_bn (BatchNormal (None, None, None, 9 3968        conv5_block15_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_0_relu (Activatio (None, None, None, 9 0           conv5_block16_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block16_1_conv (Conv2D)   (None, None, None, 1 126976      conv5_block16_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_1_bn (BatchNormal (None, None, None, 1 512         conv5_block16_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_1_relu (Activatio (None, None, None, 1 0           conv5_block16_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block16_2_conv (Conv2D)   (None, None, None, 3 36864       conv5_block16_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_concat (Concatena (None, None, None, 1 0           conv5_block15_concat[0][0]       \n                                                                 conv5_block16_2_conv[0][0]       \n__________________________________________________________________________________________________\nbn (BatchNormalization)         (None, None, None, 1 4096        conv5_block16_concat[0][0]       \n__________________________________________________________________________________________________\nrelu (Activation)               (None, None, None, 1 0           bn[0][0]                         \n__________________________________________________________________________________________________\navg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n==================================================================================================\nTotal params: 7,037,504\nTrainable params: 6,953,856\nNon-trainable params: 83,648\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i, layer in enumerate(model.layers):\n#     print(i, layer.name)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_final_model = base_model1","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_train = bottleneck_final_model.predict_generator(train_generator, predict_size_train, max_q_size=1, pickle_safe=False)\nnp.save(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_validation = bottleneck_final_model.predict_generator(validation_generator, predict_size_validation)\nnp.save(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_test = bottleneck_final_model.predict_generator(test_generator, predict_size_test)\nnp.save(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n# from keras.backend.tensorflow_backend import get_session\n# from keras.backend.tensorflow_backend import clear_session\n# from keras.backend.tensorflow_backend import set_session\n\n# def reset_keras_tf_session():\n#     \"\"\"\n#     this function clears the gpu memory and set the \n#     tf session to not use the whole gpu\n#     \"\"\"\n#     sess = get_session()\n#     clear_session()\n#     sess.close()\n#     sess = get_session()\n\n# #     config = tf.ConfigProto()\n# #     config.gpu_options.allow_growth = True\n# #     set_session(tf.Session(config=config))\n\n# reset_keras_tf_session()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = np.load(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy')\nvalidation_data = np.load(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy')\ntest_data = np.load(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy')\n\ntrain_labels = train_generator.classes\ntrain_labels = to_categorical(train_labels, num_classes=num_classes)\n\nvalidation_labels = validation_generator.classes\nvalidation_labels = to_categorical(validation_labels, num_classes=num_classes)\n\ntest_labels = test_generator.classes\ntest_labels = to_categorical(test_labels, num_classes=num_classes)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam_opt=Adam(lr=0.0001, beta_1=0.8, beta_2=0.9)\n\nmodel = Sequential()\nmodel.add(Dense(2048, activation=\"relu\", kernel_regularizer=l2(1e-06), bias_regularizer=l2(0.01), activity_regularizer=l1(1e-07)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1024, activation=\"relu\", kernel_regularizer=l2(1e-06), bias_regularizer=l2(0.01), activity_regularizer=l1(1e-07)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(512, activation=\"relu\", kernel_regularizer=l2(1e-06), bias_regularizer=l2(0.01), activity_regularizer=l1(1e-07)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes, activation=\"softmax\"))\n\nmodel.compile(optimizer=adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_data, train_labels,\n                    epochs=epochs,\n                    batch_size=batch_size,\n                    validation_data=(validation_data, validation_labels),\n                    verbose= 2)\n","execution_count":null,"outputs":[{"output_type":"stream","text":"Train on 2325 samples, validate on 994 samples\nEpoch 1/1000\n - 3s - loss: 1.2166 - acc: 0.5583 - val_loss: 0.8628 - val_acc: 0.7093\nEpoch 2/1000\n - 0s - loss: 0.9189 - acc: 0.6753 - val_loss: 0.7454 - val_acc: 0.7254\nEpoch 3/1000\n - 0s - loss: 0.8152 - acc: 0.7127 - val_loss: 0.6872 - val_acc: 0.7586\nEpoch 4/1000\n - 0s - loss: 0.7724 - acc: 0.7170 - val_loss: 0.6546 - val_acc: 0.7626\nEpoch 5/1000\n - 0s - loss: 0.7308 - acc: 0.7325 - val_loss: 0.6411 - val_acc: 0.7666\nEpoch 6/1000\n - 0s - loss: 0.6799 - acc: 0.7475 - val_loss: 0.6237 - val_acc: 0.7676\nEpoch 7/1000\n - 0s - loss: 0.6610 - acc: 0.7544 - val_loss: 0.6128 - val_acc: 0.7807\nEpoch 8/1000\n - 0s - loss: 0.6303 - acc: 0.7639 - val_loss: 0.6015 - val_acc: 0.7817\nEpoch 9/1000\n - 0s - loss: 0.6276 - acc: 0.7695 - val_loss: 0.5900 - val_acc: 0.7867\nEpoch 10/1000\n - 0s - loss: 0.6247 - acc: 0.7682 - val_loss: 0.5849 - val_acc: 0.7767\nEpoch 11/1000\n - 0s - loss: 0.6074 - acc: 0.7647 - val_loss: 0.5763 - val_acc: 0.7807\nEpoch 12/1000\n - 0s - loss: 0.5910 - acc: 0.7781 - val_loss: 0.5727 - val_acc: 0.7918\nEpoch 13/1000\n - 0s - loss: 0.5846 - acc: 0.7785 - val_loss: 0.5641 - val_acc: 0.7928\nEpoch 14/1000\n - 0s - loss: 0.5655 - acc: 0.7888 - val_loss: 0.5979 - val_acc: 0.7616\nEpoch 15/1000\n - 0s - loss: 0.5647 - acc: 0.7815 - val_loss: 0.5646 - val_acc: 0.7827\nEpoch 16/1000\n - 0s - loss: 0.5694 - acc: 0.7828 - val_loss: 0.5570 - val_acc: 0.7867\nEpoch 17/1000\n - 0s - loss: 0.5556 - acc: 0.7953 - val_loss: 0.5476 - val_acc: 0.7958\nEpoch 18/1000\n - 0s - loss: 0.5423 - acc: 0.7940 - val_loss: 0.5729 - val_acc: 0.7706\nEpoch 19/1000\n - 0s - loss: 0.5336 - acc: 0.7996 - val_loss: 0.5450 - val_acc: 0.7918\nEpoch 20/1000\n - 0s - loss: 0.5331 - acc: 0.8077 - val_loss: 0.5468 - val_acc: 0.7857\nEpoch 21/1000\n - 0s - loss: 0.5249 - acc: 0.8022 - val_loss: 0.5423 - val_acc: 0.7918\nEpoch 22/1000\n - 0s - loss: 0.5125 - acc: 0.8056 - val_loss: 0.5526 - val_acc: 0.7988\nEpoch 23/1000\n - 0s - loss: 0.5138 - acc: 0.8047 - val_loss: 0.5571 - val_acc: 0.7907\nEpoch 24/1000\n - 0s - loss: 0.5110 - acc: 0.8030 - val_loss: 0.5400 - val_acc: 0.7938\nEpoch 25/1000\n - 0s - loss: 0.4972 - acc: 0.8082 - val_loss: 0.5283 - val_acc: 0.7968\nEpoch 26/1000\n - 0s - loss: 0.4884 - acc: 0.8133 - val_loss: 0.5469 - val_acc: 0.7837\nEpoch 27/1000\n - 0s - loss: 0.4695 - acc: 0.8215 - val_loss: 0.5658 - val_acc: 0.7837\nEpoch 28/1000\n - 0s - loss: 0.4970 - acc: 0.8129 - val_loss: 0.5222 - val_acc: 0.7998\nEpoch 29/1000\n - 0s - loss: 0.4723 - acc: 0.8133 - val_loss: 0.5227 - val_acc: 0.8048\nEpoch 30/1000\n - 0s - loss: 0.4605 - acc: 0.8292 - val_loss: 0.5364 - val_acc: 0.7978\nEpoch 31/1000\n - 0s - loss: 0.4576 - acc: 0.8318 - val_loss: 0.5343 - val_acc: 0.7968\nEpoch 32/1000\n - 0s - loss: 0.4602 - acc: 0.8249 - val_loss: 0.5313 - val_acc: 0.8028\nEpoch 33/1000\n - 0s - loss: 0.4381 - acc: 0.8318 - val_loss: 0.5500 - val_acc: 0.7938\nEpoch 34/1000\n - 0s - loss: 0.4487 - acc: 0.8314 - val_loss: 0.5229 - val_acc: 0.8058\nEpoch 35/1000\n - 0s - loss: 0.4362 - acc: 0.8314 - val_loss: 0.5260 - val_acc: 0.7988\nEpoch 36/1000\n - 0s - loss: 0.4342 - acc: 0.8331 - val_loss: 0.5055 - val_acc: 0.8089\nEpoch 37/1000\n - 0s - loss: 0.4331 - acc: 0.8366 - val_loss: 0.5479 - val_acc: 0.7887\nEpoch 38/1000\n - 0s - loss: 0.4109 - acc: 0.8417 - val_loss: 0.5294 - val_acc: 0.7928\nEpoch 39/1000\n - 0s - loss: 0.4152 - acc: 0.8404 - val_loss: 0.5556 - val_acc: 0.7928\nEpoch 40/1000\n - 0s - loss: 0.4339 - acc: 0.8340 - val_loss: 0.5088 - val_acc: 0.8159\nEpoch 41/1000\n - 0s - loss: 0.3969 - acc: 0.8555 - val_loss: 0.5208 - val_acc: 0.8139\nEpoch 42/1000\n - 0s - loss: 0.4100 - acc: 0.8503 - val_loss: 0.5372 - val_acc: 0.7978\nEpoch 43/1000\n - 0s - loss: 0.4018 - acc: 0.8465 - val_loss: 0.5167 - val_acc: 0.8018\nEpoch 44/1000\n - 0s - loss: 0.4010 - acc: 0.8499 - val_loss: 0.5457 - val_acc: 0.8048\nEpoch 45/1000\n - 0s - loss: 0.3770 - acc: 0.8589 - val_loss: 0.5250 - val_acc: 0.8028\nEpoch 46/1000\n - 0s - loss: 0.3732 - acc: 0.8576 - val_loss: 0.5130 - val_acc: 0.8179\nEpoch 47/1000\n - 0s - loss: 0.3678 - acc: 0.8581 - val_loss: 0.5253 - val_acc: 0.8139\nEpoch 48/1000\n - 0s - loss: 0.3771 - acc: 0.8611 - val_loss: 0.5200 - val_acc: 0.8068\nEpoch 49/1000\n - 0s - loss: 0.3587 - acc: 0.8606 - val_loss: 0.6103 - val_acc: 0.7767\nEpoch 50/1000\n - 0s - loss: 0.3486 - acc: 0.8658 - val_loss: 0.5294 - val_acc: 0.8129\nEpoch 51/1000\n - 0s - loss: 0.3656 - acc: 0.8645 - val_loss: 0.5221 - val_acc: 0.8129\nEpoch 52/1000\n - 0s - loss: 0.3425 - acc: 0.8778 - val_loss: 0.5400 - val_acc: 0.8048\nEpoch 53/1000\n - 0s - loss: 0.3529 - acc: 0.8619 - val_loss: 0.5245 - val_acc: 0.8159\nEpoch 54/1000\n - 0s - loss: 0.3319 - acc: 0.8753 - val_loss: 0.5335 - val_acc: 0.8199\nEpoch 55/1000\n - 0s - loss: 0.3301 - acc: 0.8778 - val_loss: 0.5350 - val_acc: 0.8089\nEpoch 56/1000\n - 0s - loss: 0.3430 - acc: 0.8740 - val_loss: 0.5313 - val_acc: 0.8129\nEpoch 57/1000\n - 0s - loss: 0.3304 - acc: 0.8787 - val_loss: 0.5298 - val_acc: 0.8159\nEpoch 58/1000\n - 0s - loss: 0.3265 - acc: 0.8766 - val_loss: 0.5373 - val_acc: 0.8189\nEpoch 59/1000\n - 0s - loss: 0.3181 - acc: 0.8843 - val_loss: 0.5581 - val_acc: 0.8109\nEpoch 60/1000\n - 0s - loss: 0.3014 - acc: 0.8817 - val_loss: 0.5405 - val_acc: 0.8209\nEpoch 61/1000\n - 0s - loss: 0.3053 - acc: 0.8869 - val_loss: 0.5568 - val_acc: 0.8169\nEpoch 62/1000\n - 0s - loss: 0.2924 - acc: 0.8822 - val_loss: 0.5659 - val_acc: 0.8129\nEpoch 63/1000\n - 0s - loss: 0.2920 - acc: 0.8882 - val_loss: 0.6309 - val_acc: 0.7887\nEpoch 64/1000\n - 0s - loss: 0.2817 - acc: 0.8938 - val_loss: 0.5567 - val_acc: 0.8169\nEpoch 65/1000\n - 0s - loss: 0.2868 - acc: 0.8955 - val_loss: 0.5688 - val_acc: 0.8219\nEpoch 66/1000\n - 0s - loss: 0.2714 - acc: 0.9024 - val_loss: 0.5720 - val_acc: 0.8179\nEpoch 67/1000\n - 0s - loss: 0.2710 - acc: 0.9041 - val_loss: 0.5620 - val_acc: 0.8320\nEpoch 68/1000\n - 0s - loss: 0.2599 - acc: 0.8998 - val_loss: 0.6040 - val_acc: 0.8109\nEpoch 69/1000\n - 0s - loss: 0.2564 - acc: 0.9015 - val_loss: 0.6037 - val_acc: 0.8058\nEpoch 70/1000\n - 0s - loss: 0.2600 - acc: 0.9019 - val_loss: 0.5878 - val_acc: 0.8280\nEpoch 71/1000\n - 0s - loss: 0.2507 - acc: 0.9088 - val_loss: 0.5919 - val_acc: 0.8129\nEpoch 72/1000\n - 0s - loss: 0.2462 - acc: 0.9114 - val_loss: 0.5705 - val_acc: 0.8239\nEpoch 73/1000\n - 0s - loss: 0.2412 - acc: 0.9049 - val_loss: 0.5988 - val_acc: 0.8179\nEpoch 74/1000\n - 0s - loss: 0.2449 - acc: 0.9092 - val_loss: 0.5976 - val_acc: 0.8179\nEpoch 75/1000\n - 0s - loss: 0.2426 - acc: 0.9054 - val_loss: 0.5996 - val_acc: 0.8159\nEpoch 76/1000\n - 0s - loss: 0.2347 - acc: 0.9161 - val_loss: 0.6394 - val_acc: 0.8159\nEpoch 77/1000\n - 0s - loss: 0.2216 - acc: 0.9174 - val_loss: 0.5760 - val_acc: 0.8179\nEpoch 78/1000\n - 0s - loss: 0.2227 - acc: 0.9234 - val_loss: 0.6014 - val_acc: 0.8129\nEpoch 79/1000\n - 0s - loss: 0.2229 - acc: 0.9187 - val_loss: 0.5984 - val_acc: 0.8189\nEpoch 80/1000\n - 0s - loss: 0.2221 - acc: 0.9118 - val_loss: 0.6312 - val_acc: 0.8169\nEpoch 81/1000\n - 0s - loss: 0.2182 - acc: 0.9213 - val_loss: 0.6132 - val_acc: 0.8169\nEpoch 82/1000\n - 0s - loss: 0.1999 - acc: 0.9273 - val_loss: 0.6352 - val_acc: 0.8249\nEpoch 83/1000\n - 0s - loss: 0.1940 - acc: 0.9269 - val_loss: 0.6646 - val_acc: 0.8199\nEpoch 84/1000\n - 0s - loss: 0.2096 - acc: 0.9213 - val_loss: 0.6360 - val_acc: 0.8280\nEpoch 85/1000\n - 0s - loss: 0.1859 - acc: 0.9316 - val_loss: 0.6812 - val_acc: 0.8078\nEpoch 86/1000\n - 0s - loss: 0.1820 - acc: 0.9299 - val_loss: 0.6673 - val_acc: 0.8270\nEpoch 87/1000\n - 0s - loss: 0.1817 - acc: 0.9286 - val_loss: 0.6433 - val_acc: 0.8310\nEpoch 88/1000\n - 0s - loss: 0.1826 - acc: 0.9295 - val_loss: 0.6996 - val_acc: 0.8199\nEpoch 89/1000\n - 0s - loss: 0.1768 - acc: 0.9342 - val_loss: 0.7312 - val_acc: 0.8219\nEpoch 90/1000\n - 0s - loss: 0.1765 - acc: 0.9299 - val_loss: 0.6618 - val_acc: 0.8260\nEpoch 91/1000\n - 0s - loss: 0.1682 - acc: 0.9398 - val_loss: 0.7108 - val_acc: 0.8159\nEpoch 92/1000\n - 0s - loss: 0.1607 - acc: 0.9428 - val_loss: 0.7117 - val_acc: 0.8179\nEpoch 93/1000\n - 0s - loss: 0.1672 - acc: 0.9376 - val_loss: 0.6841 - val_acc: 0.8260\nEpoch 94/1000\n - 0s - loss: 0.1674 - acc: 0.9368 - val_loss: 0.7851 - val_acc: 0.8229\nEpoch 95/1000\n - 0s - loss: 0.1703 - acc: 0.9359 - val_loss: 0.7150 - val_acc: 0.8058\n","name":"stdout"},{"output_type":"stream","text":"Epoch 96/1000\n - 0s - loss: 0.1532 - acc: 0.9462 - val_loss: 0.7227 - val_acc: 0.8310\nEpoch 97/1000\n - 0s - loss: 0.1435 - acc: 0.9505 - val_loss: 0.7737 - val_acc: 0.8209\nEpoch 98/1000\n - 0s - loss: 0.1612 - acc: 0.9381 - val_loss: 0.7612 - val_acc: 0.8068\nEpoch 99/1000\n - 0s - loss: 0.1560 - acc: 0.9445 - val_loss: 0.7676 - val_acc: 0.8189\nEpoch 100/1000\n - 0s - loss: 0.1452 - acc: 0.9527 - val_loss: 0.7426 - val_acc: 0.8058\nEpoch 101/1000\n - 0s - loss: 0.1631 - acc: 0.9445 - val_loss: 0.7469 - val_acc: 0.8149\nEpoch 102/1000\n - 0s - loss: 0.1470 - acc: 0.9467 - val_loss: 0.7739 - val_acc: 0.8159\nEpoch 103/1000\n - 0s - loss: 0.1461 - acc: 0.9471 - val_loss: 0.8268 - val_acc: 0.7918\nEpoch 104/1000\n - 0s - loss: 0.1418 - acc: 0.9471 - val_loss: 0.8062 - val_acc: 0.8149\nEpoch 105/1000\n - 0s - loss: 0.1437 - acc: 0.9505 - val_loss: 0.7484 - val_acc: 0.8249\nEpoch 106/1000\n - 0s - loss: 0.1302 - acc: 0.9600 - val_loss: 0.8079 - val_acc: 0.8109\nEpoch 107/1000\n - 0s - loss: 0.1228 - acc: 0.9596 - val_loss: 0.8037 - val_acc: 0.8199\nEpoch 108/1000\n - 0s - loss: 0.1343 - acc: 0.9510 - val_loss: 0.7652 - val_acc: 0.8189\nEpoch 109/1000\n - 0s - loss: 0.1325 - acc: 0.9523 - val_loss: 0.8361 - val_acc: 0.8189\nEpoch 110/1000\n - 0s - loss: 0.1200 - acc: 0.9548 - val_loss: 0.8540 - val_acc: 0.8159\nEpoch 111/1000\n - 0s - loss: 0.1234 - acc: 0.9587 - val_loss: 0.7900 - val_acc: 0.8290\nEpoch 112/1000\n - 0s - loss: 0.1204 - acc: 0.9600 - val_loss: 0.8397 - val_acc: 0.8270\nEpoch 113/1000\n - 0s - loss: 0.1401 - acc: 0.9484 - val_loss: 0.7997 - val_acc: 0.8229\nEpoch 114/1000\n - 0s - loss: 0.1199 - acc: 0.9583 - val_loss: 0.9097 - val_acc: 0.8099\nEpoch 115/1000\n - 0s - loss: 0.1235 - acc: 0.9510 - val_loss: 0.8847 - val_acc: 0.7988\nEpoch 116/1000\n - 0s - loss: 0.1084 - acc: 0.9639 - val_loss: 0.8530 - val_acc: 0.8219\nEpoch 117/1000\n - 0s - loss: 0.1063 - acc: 0.9587 - val_loss: 0.8420 - val_acc: 0.8239\nEpoch 118/1000\n - 0s - loss: 0.1165 - acc: 0.9600 - val_loss: 0.8412 - val_acc: 0.8129\nEpoch 119/1000\n - 0s - loss: 0.1206 - acc: 0.9574 - val_loss: 0.8644 - val_acc: 0.8068\nEpoch 120/1000\n - 0s - loss: 0.1189 - acc: 0.9604 - val_loss: 0.8619 - val_acc: 0.8199\nEpoch 121/1000\n - 0s - loss: 0.1226 - acc: 0.9583 - val_loss: 0.8852 - val_acc: 0.8179\nEpoch 122/1000\n - 0s - loss: 0.1078 - acc: 0.9617 - val_loss: 0.8728 - val_acc: 0.8260\nEpoch 123/1000\n - 0s - loss: 0.1082 - acc: 0.9626 - val_loss: 0.8400 - val_acc: 0.8159\nEpoch 124/1000\n - 0s - loss: 0.1137 - acc: 0.9665 - val_loss: 0.9257 - val_acc: 0.8149\nEpoch 125/1000\n - 0s - loss: 0.1216 - acc: 0.9609 - val_loss: 0.8925 - val_acc: 0.8189\nEpoch 126/1000\n - 0s - loss: 0.0932 - acc: 0.9647 - val_loss: 0.9203 - val_acc: 0.8209\nEpoch 127/1000\n - 0s - loss: 0.1133 - acc: 0.9622 - val_loss: 0.9427 - val_acc: 0.8068\nEpoch 128/1000\n - 0s - loss: 0.1180 - acc: 0.9609 - val_loss: 0.8823 - val_acc: 0.8199\nEpoch 129/1000\n - 0s - loss: 0.1013 - acc: 0.9656 - val_loss: 0.8968 - val_acc: 0.8249\nEpoch 130/1000\n - 0s - loss: 0.1040 - acc: 0.9643 - val_loss: 0.9000 - val_acc: 0.8249\nEpoch 131/1000\n - 0s - loss: 0.1010 - acc: 0.9677 - val_loss: 0.9336 - val_acc: 0.8179\nEpoch 132/1000\n - 0s - loss: 0.1103 - acc: 0.9634 - val_loss: 0.8574 - val_acc: 0.8119\nEpoch 133/1000\n - 0s - loss: 0.0935 - acc: 0.9643 - val_loss: 0.9677 - val_acc: 0.8169\nEpoch 134/1000\n - 0s - loss: 0.1039 - acc: 0.9643 - val_loss: 0.9386 - val_acc: 0.8139\nEpoch 135/1000\n - 0s - loss: 0.0912 - acc: 0.9695 - val_loss: 0.9015 - val_acc: 0.8239\nEpoch 136/1000\n - 0s - loss: 0.1166 - acc: 0.9514 - val_loss: 0.8973 - val_acc: 0.8249\nEpoch 137/1000\n - 0s - loss: 0.1022 - acc: 0.9630 - val_loss: 0.8802 - val_acc: 0.8169\nEpoch 138/1000\n - 0s - loss: 0.0896 - acc: 0.9729 - val_loss: 0.9493 - val_acc: 0.8058\nEpoch 139/1000\n - 0s - loss: 0.1120 - acc: 0.9630 - val_loss: 0.9482 - val_acc: 0.8159\nEpoch 140/1000\n - 0s - loss: 0.1044 - acc: 0.9643 - val_loss: 1.0027 - val_acc: 0.8159\nEpoch 141/1000\n - 0s - loss: 0.1015 - acc: 0.9634 - val_loss: 0.9760 - val_acc: 0.8159\nEpoch 142/1000\n - 0s - loss: 0.1017 - acc: 0.9643 - val_loss: 0.9009 - val_acc: 0.8109\nEpoch 143/1000\n - 0s - loss: 0.0932 - acc: 0.9703 - val_loss: 0.9491 - val_acc: 0.8189\nEpoch 144/1000\n - 0s - loss: 0.0964 - acc: 0.9634 - val_loss: 0.9197 - val_acc: 0.8229\nEpoch 145/1000\n - 0s - loss: 0.0976 - acc: 0.9669 - val_loss: 0.9080 - val_acc: 0.8119\nEpoch 146/1000\n - 0s - loss: 0.0891 - acc: 0.9699 - val_loss: 0.9662 - val_acc: 0.8199\nEpoch 147/1000\n - 0s - loss: 0.0887 - acc: 0.9682 - val_loss: 0.9530 - val_acc: 0.8260\nEpoch 148/1000\n - 0s - loss: 0.0926 - acc: 0.9660 - val_loss: 1.0261 - val_acc: 0.8028\nEpoch 149/1000\n - 0s - loss: 0.0914 - acc: 0.9686 - val_loss: 0.9562 - val_acc: 0.8119\nEpoch 150/1000\n - 0s - loss: 0.1104 - acc: 0.9604 - val_loss: 0.9447 - val_acc: 0.8199\nEpoch 151/1000\n - 0s - loss: 0.0855 - acc: 0.9699 - val_loss: 1.0443 - val_acc: 0.7998\nEpoch 152/1000\n - 0s - loss: 0.1015 - acc: 0.9643 - val_loss: 0.9258 - val_acc: 0.8119\nEpoch 153/1000\n - 0s - loss: 0.0846 - acc: 0.9708 - val_loss: 0.9979 - val_acc: 0.8239\nEpoch 154/1000\n - 0s - loss: 0.0973 - acc: 0.9669 - val_loss: 0.9721 - val_acc: 0.8219\nEpoch 155/1000\n - 0s - loss: 0.0856 - acc: 0.9695 - val_loss: 1.0465 - val_acc: 0.8109\nEpoch 156/1000\n - 0s - loss: 0.1029 - acc: 0.9673 - val_loss: 0.9893 - val_acc: 0.8119\nEpoch 157/1000\n - 0s - loss: 0.0726 - acc: 0.9755 - val_loss: 0.9537 - val_acc: 0.8169\nEpoch 158/1000\n - 0s - loss: 0.0826 - acc: 0.9712 - val_loss: 1.0238 - val_acc: 0.8290\nEpoch 159/1000\n - 0s - loss: 0.0799 - acc: 0.9716 - val_loss: 0.9834 - val_acc: 0.8260\nEpoch 160/1000\n - 0s - loss: 0.0892 - acc: 0.9712 - val_loss: 1.0594 - val_acc: 0.8159\nEpoch 161/1000\n - 0s - loss: 0.0890 - acc: 0.9677 - val_loss: 0.9897 - val_acc: 0.8139\nEpoch 162/1000\n - 0s - loss: 0.0942 - acc: 0.9669 - val_loss: 1.0277 - val_acc: 0.8089\nEpoch 163/1000\n - 0s - loss: 0.0813 - acc: 0.9716 - val_loss: 0.9890 - val_acc: 0.8139\nEpoch 164/1000\n - 0s - loss: 0.0905 - acc: 0.9699 - val_loss: 1.0777 - val_acc: 0.8270\nEpoch 165/1000\n - 0s - loss: 0.1109 - acc: 0.9626 - val_loss: 1.0159 - val_acc: 0.8048\nEpoch 166/1000\n - 0s - loss: 0.0853 - acc: 0.9682 - val_loss: 1.0643 - val_acc: 0.8229\nEpoch 167/1000\n - 0s - loss: 0.0879 - acc: 0.9703 - val_loss: 1.0573 - val_acc: 0.8169\nEpoch 168/1000\n - 0s - loss: 0.0755 - acc: 0.9733 - val_loss: 1.0296 - val_acc: 0.8149\nEpoch 169/1000\n - 0s - loss: 0.0823 - acc: 0.9699 - val_loss: 1.0470 - val_acc: 0.8109\nEpoch 170/1000\n - 0s - loss: 0.1004 - acc: 0.9643 - val_loss: 1.0266 - val_acc: 0.8149\nEpoch 171/1000\n - 0s - loss: 0.1043 - acc: 0.9630 - val_loss: 0.9310 - val_acc: 0.8229\nEpoch 172/1000\n - 0s - loss: 0.0854 - acc: 0.9695 - val_loss: 0.9894 - val_acc: 0.8109\nEpoch 173/1000\n - 0s - loss: 0.0855 - acc: 0.9733 - val_loss: 1.0318 - val_acc: 0.8199\nEpoch 174/1000\n - 0s - loss: 0.0819 - acc: 0.9751 - val_loss: 1.0277 - val_acc: 0.8139\nEpoch 175/1000\n - 0s - loss: 0.0762 - acc: 0.9746 - val_loss: 1.1675 - val_acc: 0.8169\nEpoch 176/1000\n - 0s - loss: 0.0853 - acc: 0.9708 - val_loss: 1.0601 - val_acc: 0.7877\nEpoch 177/1000\n - 0s - loss: 0.0957 - acc: 0.9686 - val_loss: 1.0490 - val_acc: 0.8219\nEpoch 178/1000\n - 0s - loss: 0.0731 - acc: 0.9729 - val_loss: 1.0205 - val_acc: 0.8179\nEpoch 179/1000\n - 0s - loss: 0.0676 - acc: 0.9776 - val_loss: 1.0276 - val_acc: 0.8159\nEpoch 180/1000\n - 0s - loss: 0.0836 - acc: 0.9733 - val_loss: 1.0323 - val_acc: 0.8129\nEpoch 181/1000\n - 0s - loss: 0.0734 - acc: 0.9751 - val_loss: 1.0394 - val_acc: 0.8089\nEpoch 182/1000\n - 0s - loss: 0.0727 - acc: 0.9781 - val_loss: 1.0632 - val_acc: 0.8179\nEpoch 183/1000\n - 0s - loss: 0.0666 - acc: 0.9776 - val_loss: 1.1556 - val_acc: 0.8199\nEpoch 184/1000\n - 0s - loss: 0.0894 - acc: 0.9695 - val_loss: 1.0494 - val_acc: 0.8219\nEpoch 185/1000\n - 0s - loss: 0.0859 - acc: 0.9686 - val_loss: 1.0421 - val_acc: 0.8099\nEpoch 186/1000\n - 0s - loss: 0.0750 - acc: 0.9763 - val_loss: 0.9828 - val_acc: 0.8239\nEpoch 187/1000\n - 0s - loss: 0.0627 - acc: 0.9785 - val_loss: 1.0845 - val_acc: 0.8199\nEpoch 188/1000\n - 0s - loss: 0.0898 - acc: 0.9712 - val_loss: 1.1268 - val_acc: 0.8099\nEpoch 189/1000\n - 0s - loss: 0.0838 - acc: 0.9729 - val_loss: 1.0576 - val_acc: 0.8199\nEpoch 190/1000\n - 0s - loss: 0.0829 - acc: 0.9742 - val_loss: 0.9975 - val_acc: 0.8159\n","name":"stdout"},{"output_type":"stream","text":"Epoch 191/1000\n - 0s - loss: 0.0660 - acc: 0.9772 - val_loss: 1.1965 - val_acc: 0.7968\nEpoch 192/1000\n - 0s - loss: 0.0679 - acc: 0.9802 - val_loss: 1.1025 - val_acc: 0.8149\nEpoch 193/1000\n - 0s - loss: 0.0866 - acc: 0.9763 - val_loss: 1.1459 - val_acc: 0.8219\nEpoch 194/1000\n - 0s - loss: 0.0654 - acc: 0.9806 - val_loss: 1.2344 - val_acc: 0.8048\nEpoch 195/1000\n - 0s - loss: 0.0927 - acc: 0.9682 - val_loss: 1.0497 - val_acc: 0.8229\nEpoch 196/1000\n - 0s - loss: 0.0745 - acc: 0.9751 - val_loss: 1.0771 - val_acc: 0.8139\nEpoch 197/1000\n - 0s - loss: 0.0729 - acc: 0.9746 - val_loss: 1.1164 - val_acc: 0.8149\nEpoch 198/1000\n - 0s - loss: 0.0786 - acc: 0.9738 - val_loss: 1.0689 - val_acc: 0.8189\nEpoch 199/1000\n - 0s - loss: 0.0761 - acc: 0.9768 - val_loss: 1.1096 - val_acc: 0.8048\nEpoch 200/1000\n - 0s - loss: 0.0748 - acc: 0.9751 - val_loss: 1.0913 - val_acc: 0.8099\nEpoch 201/1000\n - 0s - loss: 0.0781 - acc: 0.9716 - val_loss: 1.0899 - val_acc: 0.8179\nEpoch 202/1000\n - 0s - loss: 0.0630 - acc: 0.9794 - val_loss: 1.1275 - val_acc: 0.8149\nEpoch 203/1000\n - 0s - loss: 0.0807 - acc: 0.9738 - val_loss: 1.2060 - val_acc: 0.8048\nEpoch 204/1000\n - 0s - loss: 0.0683 - acc: 0.9781 - val_loss: 1.1219 - val_acc: 0.8169\nEpoch 205/1000\n - 0s - loss: 0.0804 - acc: 0.9746 - val_loss: 1.0795 - val_acc: 0.8239\nEpoch 206/1000\n - 0s - loss: 0.0701 - acc: 0.9759 - val_loss: 1.0839 - val_acc: 0.8209\nEpoch 207/1000\n - 0s - loss: 0.0722 - acc: 0.9725 - val_loss: 1.0800 - val_acc: 0.8099\nEpoch 208/1000\n - 0s - loss: 0.0726 - acc: 0.9763 - val_loss: 1.0651 - val_acc: 0.8139\nEpoch 209/1000\n - 0s - loss: 0.0702 - acc: 0.9755 - val_loss: 1.0718 - val_acc: 0.8209\nEpoch 210/1000\n - 0s - loss: 0.0717 - acc: 0.9759 - val_loss: 1.0716 - val_acc: 0.8139\nEpoch 211/1000\n - 0s - loss: 0.0733 - acc: 0.9763 - val_loss: 1.0837 - val_acc: 0.8159\nEpoch 212/1000\n - 0s - loss: 0.0838 - acc: 0.9733 - val_loss: 1.0536 - val_acc: 0.8189\nEpoch 213/1000\n - 0s - loss: 0.0785 - acc: 0.9781 - val_loss: 1.0504 - val_acc: 0.8119\nEpoch 214/1000\n - 0s - loss: 0.0622 - acc: 0.9772 - val_loss: 1.1475 - val_acc: 0.8209\nEpoch 215/1000\n - 0s - loss: 0.0711 - acc: 0.9742 - val_loss: 1.1250 - val_acc: 0.8119\nEpoch 216/1000\n - 0s - loss: 0.0773 - acc: 0.9794 - val_loss: 1.1053 - val_acc: 0.8179\nEpoch 217/1000\n - 0s - loss: 0.0624 - acc: 0.9789 - val_loss: 1.1875 - val_acc: 0.8058\nEpoch 218/1000\n - 0s - loss: 0.0829 - acc: 0.9695 - val_loss: 1.2066 - val_acc: 0.8219\nEpoch 219/1000\n - 0s - loss: 0.0822 - acc: 0.9729 - val_loss: 1.1062 - val_acc: 0.8199\nEpoch 220/1000\n - 0s - loss: 0.0609 - acc: 0.9785 - val_loss: 1.1362 - val_acc: 0.8189\nEpoch 221/1000\n - 0s - loss: 0.0746 - acc: 0.9733 - val_loss: 1.1711 - val_acc: 0.8139\nEpoch 222/1000\n - 0s - loss: 0.0612 - acc: 0.9798 - val_loss: 1.1580 - val_acc: 0.8149\nEpoch 223/1000\n - 0s - loss: 0.0637 - acc: 0.9794 - val_loss: 1.1469 - val_acc: 0.8169\nEpoch 224/1000\n - 0s - loss: 0.0628 - acc: 0.9806 - val_loss: 1.1552 - val_acc: 0.8239\nEpoch 225/1000\n - 0s - loss: 0.0752 - acc: 0.9763 - val_loss: 1.2944 - val_acc: 0.8139\nEpoch 226/1000\n - 0s - loss: 0.0781 - acc: 0.9763 - val_loss: 1.1354 - val_acc: 0.8169\nEpoch 227/1000\n - 0s - loss: 0.0761 - acc: 0.9738 - val_loss: 1.0941 - val_acc: 0.8209\nEpoch 228/1000\n - 0s - loss: 0.0768 - acc: 0.9759 - val_loss: 1.0903 - val_acc: 0.8169\nEpoch 229/1000\n - 0s - loss: 0.0628 - acc: 0.9789 - val_loss: 1.2180 - val_acc: 0.8109\nEpoch 230/1000\n - 0s - loss: 0.0733 - acc: 0.9755 - val_loss: 1.1430 - val_acc: 0.8270\nEpoch 231/1000\n - 0s - loss: 0.0734 - acc: 0.9751 - val_loss: 1.1025 - val_acc: 0.8189\nEpoch 232/1000\n - 0s - loss: 0.0611 - acc: 0.9789 - val_loss: 1.1480 - val_acc: 0.8280\nEpoch 233/1000\n - 0s - loss: 0.0707 - acc: 0.9759 - val_loss: 1.1698 - val_acc: 0.8139\nEpoch 234/1000\n - 0s - loss: 0.0792 - acc: 0.9751 - val_loss: 1.1100 - val_acc: 0.8149\nEpoch 235/1000\n - 0s - loss: 0.0595 - acc: 0.9802 - val_loss: 1.1240 - val_acc: 0.8219\nEpoch 236/1000\n - 0s - loss: 0.0741 - acc: 0.9759 - val_loss: 1.0629 - val_acc: 0.8169\nEpoch 237/1000\n - 0s - loss: 0.0693 - acc: 0.9789 - val_loss: 1.2005 - val_acc: 0.8169\nEpoch 238/1000\n - 0s - loss: 0.0739 - acc: 0.9755 - val_loss: 1.1023 - val_acc: 0.8129\nEpoch 239/1000\n - 0s - loss: 0.0840 - acc: 0.9738 - val_loss: 1.0865 - val_acc: 0.8209\nEpoch 240/1000\n - 0s - loss: 0.0642 - acc: 0.9759 - val_loss: 1.2628 - val_acc: 0.8129\nEpoch 241/1000\n - 0s - loss: 0.0620 - acc: 0.9776 - val_loss: 1.2542 - val_acc: 0.8099\nEpoch 242/1000\n - 0s - loss: 0.0687 - acc: 0.9781 - val_loss: 1.1186 - val_acc: 0.8109\nEpoch 243/1000\n - 0s - loss: 0.0651 - acc: 0.9759 - val_loss: 1.1509 - val_acc: 0.8169\nEpoch 244/1000\n - 0s - loss: 0.0724 - acc: 0.9738 - val_loss: 1.1529 - val_acc: 0.8008\nEpoch 245/1000\n - 0s - loss: 0.0640 - acc: 0.9806 - val_loss: 1.2309 - val_acc: 0.8139\nEpoch 246/1000\n - 0s - loss: 0.0593 - acc: 0.9824 - val_loss: 1.1380 - val_acc: 0.8199\nEpoch 247/1000\n - 0s - loss: 0.0735 - acc: 0.9751 - val_loss: 1.1700 - val_acc: 0.8229\nEpoch 248/1000\n - 0s - loss: 0.0617 - acc: 0.9789 - val_loss: 1.2350 - val_acc: 0.8149\nEpoch 249/1000\n - 0s - loss: 0.0743 - acc: 0.9802 - val_loss: 1.2302 - val_acc: 0.8109\nEpoch 250/1000\n - 0s - loss: 0.0579 - acc: 0.9828 - val_loss: 1.2749 - val_acc: 0.8089\nEpoch 251/1000\n - 0s - loss: 0.0586 - acc: 0.9802 - val_loss: 1.1868 - val_acc: 0.8229\nEpoch 252/1000\n - 0s - loss: 0.0722 - acc: 0.9742 - val_loss: 1.2030 - val_acc: 0.8139\nEpoch 253/1000\n - 0s - loss: 0.0754 - acc: 0.9742 - val_loss: 1.1837 - val_acc: 0.8119\nEpoch 254/1000\n - 0s - loss: 0.0731 - acc: 0.9755 - val_loss: 1.1903 - val_acc: 0.8119\nEpoch 255/1000\n - 0s - loss: 0.0742 - acc: 0.9729 - val_loss: 1.0960 - val_acc: 0.8089\nEpoch 256/1000\n - 0s - loss: 0.0648 - acc: 0.9776 - val_loss: 1.1562 - val_acc: 0.8139\nEpoch 257/1000\n - 0s - loss: 0.0684 - acc: 0.9776 - val_loss: 1.1261 - val_acc: 0.8219\nEpoch 258/1000\n - 0s - loss: 0.0607 - acc: 0.9824 - val_loss: 1.2396 - val_acc: 0.8179\nEpoch 259/1000\n - 0s - loss: 0.0594 - acc: 0.9798 - val_loss: 1.1974 - val_acc: 0.8119\nEpoch 260/1000\n - 0s - loss: 0.0629 - acc: 0.9785 - val_loss: 1.2248 - val_acc: 0.8139\nEpoch 261/1000\n - 0s - loss: 0.0773 - acc: 0.9763 - val_loss: 1.1931 - val_acc: 0.8199\nEpoch 262/1000\n - 0s - loss: 0.0776 - acc: 0.9759 - val_loss: 1.1670 - val_acc: 0.8109\nEpoch 263/1000\n - 0s - loss: 0.0643 - acc: 0.9781 - val_loss: 1.1722 - val_acc: 0.8229\nEpoch 264/1000\n - 0s - loss: 0.0673 - acc: 0.9768 - val_loss: 1.2148 - val_acc: 0.8099\nEpoch 265/1000\n - 0s - loss: 0.0702 - acc: 0.9768 - val_loss: 1.1305 - val_acc: 0.8189\nEpoch 266/1000\n - 0s - loss: 0.0567 - acc: 0.9819 - val_loss: 1.2822 - val_acc: 0.8129\nEpoch 267/1000\n - 0s - loss: 0.0650 - acc: 0.9781 - val_loss: 1.2033 - val_acc: 0.8169\nEpoch 268/1000\n - 0s - loss: 0.0615 - acc: 0.9811 - val_loss: 1.1453 - val_acc: 0.8109\nEpoch 269/1000\n - 0s - loss: 0.0738 - acc: 0.9729 - val_loss: 1.1570 - val_acc: 0.8129\nEpoch 270/1000\n - 0s - loss: 0.0688 - acc: 0.9781 - val_loss: 1.1066 - val_acc: 0.8199\nEpoch 271/1000\n - 0s - loss: 0.0536 - acc: 0.9824 - val_loss: 1.2614 - val_acc: 0.7998\nEpoch 272/1000\n - 0s - loss: 0.0640 - acc: 0.9755 - val_loss: 1.1421 - val_acc: 0.8159\nEpoch 273/1000\n - 0s - loss: 0.0512 - acc: 0.9832 - val_loss: 1.1091 - val_acc: 0.8209\nEpoch 274/1000\n - 0s - loss: 0.0541 - acc: 0.9802 - val_loss: 1.1883 - val_acc: 0.8239\nEpoch 275/1000\n - 0s - loss: 0.0582 - acc: 0.9794 - val_loss: 1.2553 - val_acc: 0.8229\nEpoch 276/1000\n - 0s - loss: 0.0465 - acc: 0.9854 - val_loss: 1.1910 - val_acc: 0.8199\nEpoch 277/1000\n - 0s - loss: 0.0626 - acc: 0.9785 - val_loss: 1.3032 - val_acc: 0.8159\nEpoch 278/1000\n - 0s - loss: 0.0605 - acc: 0.9794 - val_loss: 1.2723 - val_acc: 0.8139\nEpoch 279/1000\n - 0s - loss: 0.0585 - acc: 0.9828 - val_loss: 1.1878 - val_acc: 0.8260\nEpoch 280/1000\n - 0s - loss: 0.0717 - acc: 0.9751 - val_loss: 1.2587 - val_acc: 0.8169\nEpoch 281/1000\n - 0s - loss: 0.0468 - acc: 0.9845 - val_loss: 1.2449 - val_acc: 0.8189\nEpoch 282/1000\n - 0s - loss: 0.0653 - acc: 0.9802 - val_loss: 1.2055 - val_acc: 0.8119\nEpoch 283/1000\n - 0s - loss: 0.0657 - acc: 0.9806 - val_loss: 1.1239 - val_acc: 0.8048\nEpoch 284/1000\n - 0s - loss: 0.0581 - acc: 0.9811 - val_loss: 1.2299 - val_acc: 0.8219\nEpoch 285/1000\n","name":"stdout"},{"output_type":"stream","text":" - 0s - loss: 0.0543 - acc: 0.9819 - val_loss: 1.2560 - val_acc: 0.8078\nEpoch 286/1000\n - 0s - loss: 0.0819 - acc: 0.9755 - val_loss: 1.1980 - val_acc: 0.8159\nEpoch 287/1000\n - 0s - loss: 0.0570 - acc: 0.9819 - val_loss: 1.1865 - val_acc: 0.8099\nEpoch 288/1000\n - 0s - loss: 0.0787 - acc: 0.9755 - val_loss: 1.1437 - val_acc: 0.8249\nEpoch 289/1000\n - 0s - loss: 0.0577 - acc: 0.9789 - val_loss: 1.3483 - val_acc: 0.8109\nEpoch 290/1000\n - 0s - loss: 0.0697 - acc: 0.9776 - val_loss: 1.2104 - val_acc: 0.8089\nEpoch 291/1000\n - 0s - loss: 0.0664 - acc: 0.9772 - val_loss: 1.1159 - val_acc: 0.8159\nEpoch 292/1000\n - 0s - loss: 0.0601 - acc: 0.9806 - val_loss: 1.2102 - val_acc: 0.7998\nEpoch 293/1000\n - 0s - loss: 0.0609 - acc: 0.9832 - val_loss: 1.1913 - val_acc: 0.8159\nEpoch 294/1000\n - 0s - loss: 0.0590 - acc: 0.9811 - val_loss: 1.2135 - val_acc: 0.8169\nEpoch 295/1000\n - 0s - loss: 0.0546 - acc: 0.9802 - val_loss: 1.3611 - val_acc: 0.8109\nEpoch 296/1000\n - 0s - loss: 0.0676 - acc: 0.9768 - val_loss: 1.2494 - val_acc: 0.8169\nEpoch 297/1000\n - 0s - loss: 0.0664 - acc: 0.9776 - val_loss: 1.2254 - val_acc: 0.8169\nEpoch 298/1000\n - 0s - loss: 0.0617 - acc: 0.9819 - val_loss: 1.1985 - val_acc: 0.8179\nEpoch 299/1000\n - 0s - loss: 0.0642 - acc: 0.9811 - val_loss: 1.1636 - val_acc: 0.8119\nEpoch 300/1000\n - 0s - loss: 0.0592 - acc: 0.9794 - val_loss: 1.3155 - val_acc: 0.8129\nEpoch 301/1000\n - 0s - loss: 0.0584 - acc: 0.9798 - val_loss: 1.2680 - val_acc: 0.8068\nEpoch 302/1000\n - 0s - loss: 0.0729 - acc: 0.9772 - val_loss: 1.1602 - val_acc: 0.8119\nEpoch 303/1000\n - 0s - loss: 0.0529 - acc: 0.9824 - val_loss: 1.1770 - val_acc: 0.8209\nEpoch 304/1000\n - 0s - loss: 0.0632 - acc: 0.9798 - val_loss: 1.1801 - val_acc: 0.8239\nEpoch 305/1000\n - 0s - loss: 0.0668 - acc: 0.9742 - val_loss: 1.1946 - val_acc: 0.8149\nEpoch 306/1000\n - 0s - loss: 0.0692 - acc: 0.9798 - val_loss: 1.1610 - val_acc: 0.8199\nEpoch 307/1000\n - 0s - loss: 0.0570 - acc: 0.9798 - val_loss: 1.1376 - val_acc: 0.8189\nEpoch 308/1000\n - 0s - loss: 0.0491 - acc: 0.9841 - val_loss: 1.3037 - val_acc: 0.8119\nEpoch 309/1000\n - 0s - loss: 0.0523 - acc: 0.9815 - val_loss: 1.2632 - val_acc: 0.8159\nEpoch 310/1000\n - 0s - loss: 0.0642 - acc: 0.9798 - val_loss: 1.1675 - val_acc: 0.8109\nEpoch 311/1000\n - 0s - loss: 0.0660 - acc: 0.9772 - val_loss: 1.1175 - val_acc: 0.8149\nEpoch 312/1000\n - 0s - loss: 0.0653 - acc: 0.9776 - val_loss: 1.3601 - val_acc: 0.8119\nEpoch 313/1000\n - 0s - loss: 0.0652 - acc: 0.9772 - val_loss: 1.2108 - val_acc: 0.8139\nEpoch 314/1000\n - 0s - loss: 0.0627 - acc: 0.9763 - val_loss: 1.2533 - val_acc: 0.8089\nEpoch 315/1000\n - 0s - loss: 0.0615 - acc: 0.9789 - val_loss: 1.2078 - val_acc: 0.8219\nEpoch 316/1000\n - 0s - loss: 0.0500 - acc: 0.9845 - val_loss: 1.2918 - val_acc: 0.8109\nEpoch 317/1000\n - 0s - loss: 0.0637 - acc: 0.9785 - val_loss: 1.2390 - val_acc: 0.8169\nEpoch 318/1000\n - 0s - loss: 0.0535 - acc: 0.9824 - val_loss: 1.3034 - val_acc: 0.8149\nEpoch 319/1000\n - 0s - loss: 0.0697 - acc: 0.9763 - val_loss: 1.2925 - val_acc: 0.8149\nEpoch 320/1000\n - 0s - loss: 0.0501 - acc: 0.9845 - val_loss: 1.2236 - val_acc: 0.8129\nEpoch 321/1000\n - 0s - loss: 0.0683 - acc: 0.9781 - val_loss: 1.2954 - val_acc: 0.8078\nEpoch 322/1000\n - 0s - loss: 0.0618 - acc: 0.9785 - val_loss: 1.2046 - val_acc: 0.8099\nEpoch 323/1000\n - 0s - loss: 0.0578 - acc: 0.9824 - val_loss: 1.2717 - val_acc: 0.8179\nEpoch 324/1000\n - 0s - loss: 0.0599 - acc: 0.9819 - val_loss: 1.3123 - val_acc: 0.8038\nEpoch 325/1000\n - 0s - loss: 0.0556 - acc: 0.9824 - val_loss: 1.2199 - val_acc: 0.8139\nEpoch 326/1000\n - 0s - loss: 0.0763 - acc: 0.9759 - val_loss: 1.2192 - val_acc: 0.8068\nEpoch 327/1000\n - 0s - loss: 0.0609 - acc: 0.9772 - val_loss: 1.2628 - val_acc: 0.8028\nEpoch 328/1000\n - 0s - loss: 0.0722 - acc: 0.9742 - val_loss: 1.2707 - val_acc: 0.8129\nEpoch 329/1000\n - 0s - loss: 0.0644 - acc: 0.9755 - val_loss: 1.2261 - val_acc: 0.8159\nEpoch 330/1000\n - 0s - loss: 0.0650 - acc: 0.9768 - val_loss: 1.2885 - val_acc: 0.8199\nEpoch 331/1000\n - 0s - loss: 0.0626 - acc: 0.9794 - val_loss: 1.3286 - val_acc: 0.8099\nEpoch 332/1000\n - 0s - loss: 0.0621 - acc: 0.9772 - val_loss: 1.1788 - val_acc: 0.8209\nEpoch 333/1000\n - 0s - loss: 0.0649 - acc: 0.9806 - val_loss: 1.1770 - val_acc: 0.8209\nEpoch 334/1000\n - 0s - loss: 0.0544 - acc: 0.9811 - val_loss: 1.2884 - val_acc: 0.8139\nEpoch 335/1000\n - 0s - loss: 0.0703 - acc: 0.9772 - val_loss: 1.2064 - val_acc: 0.8078\nEpoch 336/1000\n - 0s - loss: 0.0582 - acc: 0.9806 - val_loss: 1.1780 - val_acc: 0.8058\nEpoch 337/1000\n - 0s - loss: 0.0499 - acc: 0.9854 - val_loss: 1.2910 - val_acc: 0.8139\nEpoch 338/1000\n - 0s - loss: 0.0684 - acc: 0.9789 - val_loss: 1.2377 - val_acc: 0.8058\nEpoch 339/1000\n - 0s - loss: 0.0657 - acc: 0.9781 - val_loss: 1.2269 - val_acc: 0.8129\nEpoch 340/1000\n - 0s - loss: 0.0482 - acc: 0.9849 - val_loss: 1.3649 - val_acc: 0.8089\nEpoch 341/1000\n - 0s - loss: 0.0670 - acc: 0.9781 - val_loss: 1.3158 - val_acc: 0.8078\nEpoch 342/1000\n - 0s - loss: 0.0634 - acc: 0.9802 - val_loss: 1.2265 - val_acc: 0.8099\nEpoch 343/1000\n - 0s - loss: 0.0634 - acc: 0.9798 - val_loss: 1.3118 - val_acc: 0.8109\nEpoch 344/1000\n - 0s - loss: 0.0701 - acc: 0.9776 - val_loss: 1.2129 - val_acc: 0.8149\nEpoch 345/1000\n - 0s - loss: 0.0508 - acc: 0.9845 - val_loss: 1.2344 - val_acc: 0.8199\nEpoch 346/1000\n - 0s - loss: 0.0671 - acc: 0.9781 - val_loss: 1.3151 - val_acc: 0.8078\nEpoch 347/1000\n - 0s - loss: 0.0805 - acc: 0.9781 - val_loss: 1.0837 - val_acc: 0.8179\nEpoch 348/1000\n - 0s - loss: 0.0470 - acc: 0.9824 - val_loss: 1.2627 - val_acc: 0.8159\nEpoch 349/1000\n - 0s - loss: 0.0656 - acc: 0.9768 - val_loss: 1.2364 - val_acc: 0.8189\nEpoch 350/1000\n - 0s - loss: 0.0576 - acc: 0.9776 - val_loss: 1.2468 - val_acc: 0.8179\nEpoch 351/1000\n - 0s - loss: 0.0641 - acc: 0.9768 - val_loss: 1.2153 - val_acc: 0.8169\nEpoch 352/1000\n - 0s - loss: 0.0647 - acc: 0.9798 - val_loss: 1.1845 - val_acc: 0.8219\nEpoch 353/1000\n - 0s - loss: 0.0603 - acc: 0.9789 - val_loss: 1.2139 - val_acc: 0.8209\nEpoch 354/1000\n - 0s - loss: 0.0527 - acc: 0.9841 - val_loss: 1.3432 - val_acc: 0.8219\nEpoch 355/1000\n - 0s - loss: 0.0706 - acc: 0.9785 - val_loss: 1.3226 - val_acc: 0.8159\nEpoch 356/1000\n - 0s - loss: 0.0700 - acc: 0.9776 - val_loss: 1.2719 - val_acc: 0.8099\nEpoch 357/1000\n - 0s - loss: 0.0670 - acc: 0.9751 - val_loss: 1.2406 - val_acc: 0.8199\nEpoch 358/1000\n - 0s - loss: 0.0488 - acc: 0.9828 - val_loss: 1.2553 - val_acc: 0.8179\nEpoch 359/1000\n - 0s - loss: 0.0550 - acc: 0.9789 - val_loss: 1.2993 - val_acc: 0.8018\nEpoch 360/1000\n - 0s - loss: 0.0617 - acc: 0.9794 - val_loss: 1.3144 - val_acc: 0.8119\nEpoch 361/1000\n - 0s - loss: 0.0585 - acc: 0.9794 - val_loss: 1.2233 - val_acc: 0.8199\nEpoch 362/1000\n - 0s - loss: 0.0525 - acc: 0.9828 - val_loss: 1.3701 - val_acc: 0.8099\nEpoch 363/1000\n - 0s - loss: 0.0475 - acc: 0.9837 - val_loss: 1.3127 - val_acc: 0.8199\nEpoch 364/1000\n - 0s - loss: 0.0531 - acc: 0.9811 - val_loss: 1.3609 - val_acc: 0.8209\nEpoch 365/1000\n - 0s - loss: 0.0606 - acc: 0.9781 - val_loss: 1.3365 - val_acc: 0.8260\nEpoch 366/1000\n - 0s - loss: 0.0484 - acc: 0.9828 - val_loss: 1.4903 - val_acc: 0.8119\nEpoch 367/1000\n - 0s - loss: 0.0544 - acc: 0.9824 - val_loss: 1.3869 - val_acc: 0.8149\nEpoch 368/1000\n - 0s - loss: 0.0707 - acc: 0.9772 - val_loss: 1.2323 - val_acc: 0.8139\nEpoch 369/1000\n - 0s - loss: 0.0443 - acc: 0.9837 - val_loss: 1.2628 - val_acc: 0.8159\nEpoch 370/1000\n - 0s - loss: 0.0531 - acc: 0.9811 - val_loss: 1.3637 - val_acc: 0.8129\nEpoch 371/1000\n - 0s - loss: 0.0457 - acc: 0.9854 - val_loss: 1.5356 - val_acc: 0.8099\nEpoch 372/1000\n - 0s - loss: 0.0650 - acc: 0.9794 - val_loss: 1.1653 - val_acc: 0.8089\nEpoch 373/1000\n - 0s - loss: 0.0586 - acc: 0.9815 - val_loss: 1.2627 - val_acc: 0.8159\nEpoch 374/1000\n - 0s - loss: 0.0607 - acc: 0.9849 - val_loss: 1.2088 - val_acc: 0.8149\nEpoch 375/1000\n - 0s - loss: 0.0541 - acc: 0.9794 - val_loss: 1.3575 - val_acc: 0.8078\nEpoch 376/1000\n - 0s - loss: 0.0749 - acc: 0.9759 - val_loss: 1.2104 - val_acc: 0.8149\nEpoch 377/1000\n - 0s - loss: 0.0473 - acc: 0.9841 - val_loss: 1.1708 - val_acc: 0.8229\nEpoch 378/1000\n - 0s - loss: 0.0410 - acc: 0.9884 - val_loss: 1.2716 - val_acc: 0.8229\nEpoch 379/1000\n - 0s - loss: 0.0613 - acc: 0.9806 - val_loss: 1.2492 - val_acc: 0.8229\n","name":"stdout"},{"output_type":"stream","text":"Epoch 380/1000\n - 0s - loss: 0.0632 - acc: 0.9789 - val_loss: 1.3054 - val_acc: 0.8229\nEpoch 381/1000\n - 0s - loss: 0.0647 - acc: 0.9763 - val_loss: 1.2758 - val_acc: 0.8139\nEpoch 382/1000\n - 0s - loss: 0.0524 - acc: 0.9828 - val_loss: 1.2647 - val_acc: 0.8119\nEpoch 383/1000\n - 0s - loss: 0.0529 - acc: 0.9794 - val_loss: 1.3423 - val_acc: 0.8149\nEpoch 384/1000\n - 0s - loss: 0.0685 - acc: 0.9781 - val_loss: 1.1711 - val_acc: 0.8099\nEpoch 385/1000\n - 0s - loss: 0.0519 - acc: 0.9811 - val_loss: 1.2825 - val_acc: 0.8159\nEpoch 386/1000\n - 0s - loss: 0.0499 - acc: 0.9828 - val_loss: 1.3648 - val_acc: 0.8119\nEpoch 387/1000\n - 0s - loss: 0.0507 - acc: 0.9832 - val_loss: 1.3869 - val_acc: 0.8119\nEpoch 388/1000\n - 0s - loss: 0.0718 - acc: 0.9789 - val_loss: 1.2998 - val_acc: 0.8149\nEpoch 389/1000\n - 0s - loss: 0.0539 - acc: 0.9832 - val_loss: 1.2294 - val_acc: 0.8099\nEpoch 390/1000\n - 0s - loss: 0.0483 - acc: 0.9819 - val_loss: 1.3576 - val_acc: 0.8179\nEpoch 391/1000\n - 0s - loss: 0.0707 - acc: 0.9785 - val_loss: 1.2122 - val_acc: 0.8089\nEpoch 392/1000\n - 0s - loss: 0.0449 - acc: 0.9849 - val_loss: 1.4043 - val_acc: 0.7998\nEpoch 393/1000\n - 0s - loss: 0.0631 - acc: 0.9776 - val_loss: 1.2558 - val_acc: 0.8229\nEpoch 394/1000\n - 0s - loss: 0.0573 - acc: 0.9768 - val_loss: 1.1931 - val_acc: 0.8179\nEpoch 395/1000\n - 0s - loss: 0.0500 - acc: 0.9867 - val_loss: 1.2894 - val_acc: 0.8159\nEpoch 396/1000\n - 0s - loss: 0.0770 - acc: 0.9776 - val_loss: 1.1457 - val_acc: 0.8078\nEpoch 397/1000\n - 0s - loss: 0.0526 - acc: 0.9815 - val_loss: 1.2231 - val_acc: 0.8109\nEpoch 398/1000\n - 0s - loss: 0.0456 - acc: 0.9862 - val_loss: 1.3169 - val_acc: 0.8260\nEpoch 399/1000\n - 0s - loss: 0.0504 - acc: 0.9802 - val_loss: 1.3869 - val_acc: 0.8179\nEpoch 400/1000\n - 0s - loss: 0.0602 - acc: 0.9815 - val_loss: 1.2888 - val_acc: 0.8109\nEpoch 401/1000\n - 0s - loss: 0.0591 - acc: 0.9824 - val_loss: 1.3450 - val_acc: 0.8169\nEpoch 402/1000\n - 0s - loss: 0.0528 - acc: 0.9832 - val_loss: 1.2968 - val_acc: 0.8068\nEpoch 403/1000\n - 0s - loss: 0.0553 - acc: 0.9815 - val_loss: 1.2274 - val_acc: 0.8159\nEpoch 404/1000\n - 0s - loss: 0.0574 - acc: 0.9819 - val_loss: 1.1937 - val_acc: 0.8099\nEpoch 405/1000\n - 0s - loss: 0.0457 - acc: 0.9832 - val_loss: 1.2729 - val_acc: 0.8209\nEpoch 406/1000\n - 0s - loss: 0.0467 - acc: 0.9849 - val_loss: 1.3586 - val_acc: 0.8199\nEpoch 407/1000\n - 0s - loss: 0.0513 - acc: 0.9867 - val_loss: 1.3358 - val_acc: 0.8189\nEpoch 408/1000\n - 0s - loss: 0.0499 - acc: 0.9854 - val_loss: 1.3008 - val_acc: 0.8089\nEpoch 409/1000\n - 0s - loss: 0.0544 - acc: 0.9811 - val_loss: 1.2748 - val_acc: 0.8179\nEpoch 410/1000\n - 0s - loss: 0.0457 - acc: 0.9845 - val_loss: 1.3563 - val_acc: 0.8139\nEpoch 411/1000\n - 0s - loss: 0.0540 - acc: 0.9824 - val_loss: 1.3579 - val_acc: 0.8139\nEpoch 412/1000\n - 0s - loss: 0.0760 - acc: 0.9794 - val_loss: 1.2504 - val_acc: 0.8199\nEpoch 413/1000\n - 0s - loss: 0.0636 - acc: 0.9789 - val_loss: 1.2912 - val_acc: 0.8199\nEpoch 414/1000\n - 0s - loss: 0.0613 - acc: 0.9798 - val_loss: 1.2204 - val_acc: 0.8169\nEpoch 415/1000\n - 0s - loss: 0.0529 - acc: 0.9806 - val_loss: 1.3479 - val_acc: 0.8179\nEpoch 416/1000\n - 0s - loss: 0.0580 - acc: 0.9806 - val_loss: 1.2849 - val_acc: 0.8089\nEpoch 417/1000\n - 0s - loss: 0.0442 - acc: 0.9858 - val_loss: 1.3152 - val_acc: 0.8229\nEpoch 418/1000\n - 0s - loss: 0.0493 - acc: 0.9802 - val_loss: 1.3428 - val_acc: 0.8199\nEpoch 419/1000\n - 0s - loss: 0.0549 - acc: 0.9798 - val_loss: 1.3329 - val_acc: 0.8018\nEpoch 420/1000\n - 0s - loss: 0.0555 - acc: 0.9815 - val_loss: 1.3646 - val_acc: 0.8139\nEpoch 421/1000\n - 0s - loss: 0.0626 - acc: 0.9798 - val_loss: 1.3280 - val_acc: 0.8209\nEpoch 422/1000\n - 0s - loss: 0.0704 - acc: 0.9763 - val_loss: 1.1991 - val_acc: 0.8219\nEpoch 423/1000\n - 0s - loss: 0.0641 - acc: 0.9832 - val_loss: 1.2434 - val_acc: 0.8209\nEpoch 424/1000\n - 0s - loss: 0.0503 - acc: 0.9837 - val_loss: 1.3347 - val_acc: 0.8179\nEpoch 425/1000\n - 0s - loss: 0.0491 - acc: 0.9819 - val_loss: 1.4117 - val_acc: 0.8179\nEpoch 426/1000\n - 0s - loss: 0.0506 - acc: 0.9815 - val_loss: 1.3559 - val_acc: 0.8169\nEpoch 427/1000\n - 0s - loss: 0.0514 - acc: 0.9849 - val_loss: 1.2821 - val_acc: 0.8169\nEpoch 428/1000\n - 0s - loss: 0.0587 - acc: 0.9824 - val_loss: 1.3803 - val_acc: 0.8099\nEpoch 429/1000\n - 0s - loss: 0.0667 - acc: 0.9789 - val_loss: 1.3305 - val_acc: 0.8119\nEpoch 430/1000\n - 0s - loss: 0.0619 - acc: 0.9806 - val_loss: 1.1860 - val_acc: 0.8179\nEpoch 431/1000\n - 0s - loss: 0.0619 - acc: 0.9815 - val_loss: 1.3510 - val_acc: 0.8169\nEpoch 432/1000\n - 0s - loss: 0.0528 - acc: 0.9845 - val_loss: 1.4231 - val_acc: 0.8109\nEpoch 433/1000\n - 0s - loss: 0.0408 - acc: 0.9862 - val_loss: 1.2998 - val_acc: 0.8129\nEpoch 434/1000\n - 0s - loss: 0.0435 - acc: 0.9854 - val_loss: 1.4109 - val_acc: 0.8058\nEpoch 435/1000\n - 0s - loss: 0.0523 - acc: 0.9828 - val_loss: 1.3296 - val_acc: 0.8159\nEpoch 436/1000\n - 0s - loss: 0.0516 - acc: 0.9849 - val_loss: 1.3351 - val_acc: 0.8189\nEpoch 437/1000\n - 0s - loss: 0.0580 - acc: 0.9811 - val_loss: 1.3211 - val_acc: 0.8169\nEpoch 438/1000\n - 0s - loss: 0.0518 - acc: 0.9828 - val_loss: 1.3266 - val_acc: 0.8109\nEpoch 439/1000\n - 0s - loss: 0.0619 - acc: 0.9785 - val_loss: 1.2668 - val_acc: 0.8159\nEpoch 440/1000\n - 0s - loss: 0.0535 - acc: 0.9832 - val_loss: 1.3354 - val_acc: 0.8119\nEpoch 441/1000\n - 0s - loss: 0.0504 - acc: 0.9811 - val_loss: 1.4184 - val_acc: 0.8199\nEpoch 442/1000\n - 0s - loss: 0.0564 - acc: 0.9832 - val_loss: 1.2857 - val_acc: 0.8169\nEpoch 443/1000\n - 0s - loss: 0.0561 - acc: 0.9832 - val_loss: 1.3273 - val_acc: 0.8089\nEpoch 444/1000\n - 0s - loss: 0.0548 - acc: 0.9811 - val_loss: 1.3260 - val_acc: 0.8129\nEpoch 445/1000\n - 0s - loss: 0.0607 - acc: 0.9824 - val_loss: 1.3921 - val_acc: 0.8169\nEpoch 446/1000\n - 0s - loss: 0.0486 - acc: 0.9841 - val_loss: 1.3318 - val_acc: 0.8109\nEpoch 447/1000\n - 0s - loss: 0.0511 - acc: 0.9837 - val_loss: 1.2800 - val_acc: 0.8109\nEpoch 448/1000\n - 0s - loss: 0.0552 - acc: 0.9815 - val_loss: 1.4003 - val_acc: 0.8169\nEpoch 449/1000\n - 0s - loss: 0.0532 - acc: 0.9819 - val_loss: 1.4057 - val_acc: 0.8209\nEpoch 450/1000\n - 0s - loss: 0.0617 - acc: 0.9798 - val_loss: 1.4179 - val_acc: 0.8129\nEpoch 451/1000\n - 0s - loss: 0.0636 - acc: 0.9806 - val_loss: 1.3590 - val_acc: 0.8169\nEpoch 452/1000\n - 0s - loss: 0.0537 - acc: 0.9798 - val_loss: 1.4495 - val_acc: 0.8159\nEpoch 453/1000\n - 0s - loss: 0.0585 - acc: 0.9819 - val_loss: 1.2623 - val_acc: 0.8169\nEpoch 454/1000\n - 0s - loss: 0.0505 - acc: 0.9862 - val_loss: 1.2925 - val_acc: 0.8109\nEpoch 455/1000\n - 0s - loss: 0.0505 - acc: 0.9841 - val_loss: 1.2991 - val_acc: 0.8209\nEpoch 456/1000\n - 0s - loss: 0.0532 - acc: 0.9828 - val_loss: 1.4012 - val_acc: 0.8068\nEpoch 457/1000\n - 0s - loss: 0.0461 - acc: 0.9828 - val_loss: 1.2592 - val_acc: 0.8109\nEpoch 458/1000\n - 0s - loss: 0.0501 - acc: 0.9832 - val_loss: 1.3670 - val_acc: 0.8169\nEpoch 459/1000\n - 0s - loss: 0.0627 - acc: 0.9738 - val_loss: 1.2700 - val_acc: 0.8129\nEpoch 460/1000\n - 0s - loss: 0.0613 - acc: 0.9798 - val_loss: 1.2382 - val_acc: 0.8119\nEpoch 461/1000\n - 0s - loss: 0.0491 - acc: 0.9824 - val_loss: 1.3450 - val_acc: 0.8068\nEpoch 462/1000\n - 0s - loss: 0.0556 - acc: 0.9837 - val_loss: 1.3386 - val_acc: 0.8179\nEpoch 463/1000\n - 0s - loss: 0.0480 - acc: 0.9837 - val_loss: 1.4986 - val_acc: 0.7867\nEpoch 464/1000\n - 0s - loss: 0.0515 - acc: 0.9875 - val_loss: 1.3919 - val_acc: 0.8119\nEpoch 465/1000\n - 0s - loss: 0.0527 - acc: 0.9815 - val_loss: 1.4548 - val_acc: 0.8209\nEpoch 466/1000\n - 0s - loss: 0.0501 - acc: 0.9832 - val_loss: 1.3316 - val_acc: 0.8199\nEpoch 467/1000\n - 0s - loss: 0.0658 - acc: 0.9798 - val_loss: 1.3090 - val_acc: 0.8199\nEpoch 468/1000\n - 0s - loss: 0.0423 - acc: 0.9871 - val_loss: 1.4298 - val_acc: 0.8149\nEpoch 469/1000\n - 0s - loss: 0.0506 - acc: 0.9832 - val_loss: 1.3521 - val_acc: 0.8119\nEpoch 470/1000\n - 0s - loss: 0.0618 - acc: 0.9806 - val_loss: 1.3817 - val_acc: 0.8109\nEpoch 471/1000\n - 0s - loss: 0.0473 - acc: 0.9832 - val_loss: 1.3675 - val_acc: 0.8078\nEpoch 472/1000\n - 0s - loss: 0.0469 - acc: 0.9841 - val_loss: 1.3970 - val_acc: 0.8169\nEpoch 473/1000\n - 0s - loss: 0.0560 - acc: 0.9828 - val_loss: 1.4450 - val_acc: 0.8139\nEpoch 474/1000\n","name":"stdout"},{"output_type":"stream","text":" - 0s - loss: 0.0623 - acc: 0.9776 - val_loss: 1.3123 - val_acc: 0.8159\nEpoch 475/1000\n - 0s - loss: 0.0530 - acc: 0.9811 - val_loss: 1.2795 - val_acc: 0.8179\nEpoch 476/1000\n - 0s - loss: 0.0376 - acc: 0.9867 - val_loss: 1.5190 - val_acc: 0.8089\nEpoch 477/1000\n - 0s - loss: 0.0548 - acc: 0.9794 - val_loss: 1.3975 - val_acc: 0.8129\nEpoch 478/1000\n - 0s - loss: 0.0494 - acc: 0.9824 - val_loss: 1.2399 - val_acc: 0.8139\nEpoch 479/1000\n - 0s - loss: 0.0485 - acc: 0.9854 - val_loss: 1.3720 - val_acc: 0.8149\nEpoch 480/1000\n - 0s - loss: 0.0561 - acc: 0.9811 - val_loss: 1.3704 - val_acc: 0.8099\nEpoch 481/1000\n - 0s - loss: 0.0468 - acc: 0.9828 - val_loss: 1.2754 - val_acc: 0.8229\nEpoch 482/1000\n - 0s - loss: 0.0461 - acc: 0.9867 - val_loss: 1.4567 - val_acc: 0.8139\nEpoch 483/1000\n - 0s - loss: 0.0500 - acc: 0.9837 - val_loss: 1.3396 - val_acc: 0.8189\nEpoch 484/1000\n - 0s - loss: 0.0643 - acc: 0.9794 - val_loss: 1.3222 - val_acc: 0.8179\nEpoch 485/1000\n - 0s - loss: 0.0480 - acc: 0.9854 - val_loss: 1.2585 - val_acc: 0.8159\nEpoch 486/1000\n - 0s - loss: 0.0542 - acc: 0.9837 - val_loss: 1.3795 - val_acc: 0.8089\nEpoch 487/1000\n - 0s - loss: 0.0445 - acc: 0.9837 - val_loss: 1.3457 - val_acc: 0.8089\nEpoch 488/1000\n - 0s - loss: 0.0472 - acc: 0.9832 - val_loss: 1.5203 - val_acc: 0.8038\nEpoch 489/1000\n - 0s - loss: 0.0636 - acc: 0.9815 - val_loss: 1.4016 - val_acc: 0.8209\nEpoch 490/1000\n - 0s - loss: 0.0416 - acc: 0.9867 - val_loss: 1.4437 - val_acc: 0.8109\nEpoch 491/1000\n - 0s - loss: 0.0525 - acc: 0.9819 - val_loss: 1.3801 - val_acc: 0.8058\nEpoch 492/1000\n - 0s - loss: 0.0513 - acc: 0.9819 - val_loss: 1.4992 - val_acc: 0.8139\nEpoch 493/1000\n - 0s - loss: 0.0566 - acc: 0.9828 - val_loss: 1.2984 - val_acc: 0.8078\nEpoch 494/1000\n - 0s - loss: 0.0515 - acc: 0.9832 - val_loss: 1.5107 - val_acc: 0.8159\nEpoch 495/1000\n - 0s - loss: 0.0478 - acc: 0.9841 - val_loss: 1.3661 - val_acc: 0.8068\nEpoch 496/1000\n - 0s - loss: 0.0494 - acc: 0.9841 - val_loss: 1.4091 - val_acc: 0.8139\nEpoch 497/1000\n - 0s - loss: 0.0530 - acc: 0.9837 - val_loss: 1.2693 - val_acc: 0.8119\nEpoch 498/1000\n - 0s - loss: 0.0433 - acc: 0.9854 - val_loss: 1.5304 - val_acc: 0.8109\nEpoch 499/1000\n - 0s - loss: 0.0522 - acc: 0.9824 - val_loss: 1.4181 - val_acc: 0.8129\nEpoch 500/1000\n - 0s - loss: 0.0435 - acc: 0.9858 - val_loss: 1.3401 - val_acc: 0.8119\nEpoch 501/1000\n - 0s - loss: 0.0490 - acc: 0.9819 - val_loss: 1.4603 - val_acc: 0.8058\nEpoch 502/1000\n - 0s - loss: 0.0518 - acc: 0.9845 - val_loss: 1.4671 - val_acc: 0.8139\nEpoch 503/1000\n - 0s - loss: 0.0485 - acc: 0.9794 - val_loss: 1.4144 - val_acc: 0.8129\nEpoch 504/1000\n - 0s - loss: 0.0507 - acc: 0.9828 - val_loss: 1.3727 - val_acc: 0.8189\nEpoch 505/1000\n - 0s - loss: 0.0512 - acc: 0.9828 - val_loss: 1.3468 - val_acc: 0.8068\nEpoch 506/1000\n - 0s - loss: 0.0478 - acc: 0.9837 - val_loss: 1.4858 - val_acc: 0.8189\nEpoch 507/1000\n - 0s - loss: 0.0434 - acc: 0.9867 - val_loss: 1.2557 - val_acc: 0.8229\nEpoch 508/1000\n - 0s - loss: 0.0483 - acc: 0.9845 - val_loss: 1.3683 - val_acc: 0.8129\nEpoch 509/1000\n - 0s - loss: 0.0556 - acc: 0.9837 - val_loss: 1.3465 - val_acc: 0.8189\nEpoch 510/1000\n - 0s - loss: 0.0451 - acc: 0.9880 - val_loss: 1.4152 - val_acc: 0.8129\nEpoch 511/1000\n - 0s - loss: 0.0502 - acc: 0.9824 - val_loss: 1.3007 - val_acc: 0.8058\nEpoch 512/1000\n - 0s - loss: 0.0544 - acc: 0.9824 - val_loss: 1.4117 - val_acc: 0.8109\nEpoch 513/1000\n - 0s - loss: 0.0472 - acc: 0.9858 - val_loss: 1.4527 - val_acc: 0.8169\nEpoch 514/1000\n - 0s - loss: 0.0513 - acc: 0.9802 - val_loss: 1.2121 - val_acc: 0.8159\nEpoch 515/1000\n - 0s - loss: 0.0421 - acc: 0.9854 - val_loss: 1.4344 - val_acc: 0.8099\nEpoch 516/1000\n - 0s - loss: 0.0533 - acc: 0.9802 - val_loss: 1.5479 - val_acc: 0.8129\nEpoch 517/1000\n - 0s - loss: 0.0712 - acc: 0.9789 - val_loss: 1.5217 - val_acc: 0.8159\nEpoch 518/1000\n - 0s - loss: 0.0488 - acc: 0.9794 - val_loss: 1.3882 - val_acc: 0.8169\nEpoch 519/1000\n - 0s - loss: 0.0410 - acc: 0.9867 - val_loss: 1.5153 - val_acc: 0.8119\nEpoch 520/1000\n - 0s - loss: 0.0490 - acc: 0.9806 - val_loss: 1.3143 - val_acc: 0.8169\nEpoch 521/1000\n - 0s - loss: 0.0445 - acc: 0.9858 - val_loss: 1.4085 - val_acc: 0.8159\nEpoch 522/1000\n - 0s - loss: 0.0649 - acc: 0.9811 - val_loss: 1.3667 - val_acc: 0.8139\nEpoch 523/1000\n - 0s - loss: 0.0646 - acc: 0.9798 - val_loss: 1.2584 - val_acc: 0.8149\nEpoch 524/1000\n - 0s - loss: 0.0476 - acc: 0.9798 - val_loss: 1.3805 - val_acc: 0.8159\nEpoch 525/1000\n - 0s - loss: 0.0439 - acc: 0.9858 - val_loss: 1.3853 - val_acc: 0.8199\nEpoch 526/1000\n - 0s - loss: 0.0535 - acc: 0.9824 - val_loss: 1.3453 - val_acc: 0.8129\nEpoch 527/1000\n - 0s - loss: 0.0520 - acc: 0.9854 - val_loss: 1.3146 - val_acc: 0.8139\nEpoch 528/1000\n - 0s - loss: 0.0566 - acc: 0.9798 - val_loss: 1.3250 - val_acc: 0.8179\nEpoch 529/1000\n - 0s - loss: 0.0490 - acc: 0.9832 - val_loss: 1.3968 - val_acc: 0.8099\nEpoch 530/1000\n - 0s - loss: 0.0450 - acc: 0.9837 - val_loss: 1.4707 - val_acc: 0.8159\nEpoch 531/1000\n - 0s - loss: 0.0537 - acc: 0.9798 - val_loss: 1.3216 - val_acc: 0.8119\nEpoch 532/1000\n - 0s - loss: 0.0422 - acc: 0.9854 - val_loss: 1.4482 - val_acc: 0.8038\nEpoch 533/1000\n - 0s - loss: 0.0451 - acc: 0.9832 - val_loss: 1.5157 - val_acc: 0.8129\nEpoch 534/1000\n - 0s - loss: 0.0541 - acc: 0.9815 - val_loss: 1.3640 - val_acc: 0.8149\nEpoch 535/1000\n - 0s - loss: 0.0473 - acc: 0.9815 - val_loss: 1.4637 - val_acc: 0.8169\nEpoch 536/1000\n - 0s - loss: 0.0511 - acc: 0.9811 - val_loss: 1.3876 - val_acc: 0.8058\nEpoch 537/1000\n - 0s - loss: 0.0501 - acc: 0.9845 - val_loss: 1.4250 - val_acc: 0.8270\nEpoch 538/1000\n - 0s - loss: 0.0411 - acc: 0.9828 - val_loss: 1.4323 - val_acc: 0.8159\nEpoch 539/1000\n - 0s - loss: 0.0592 - acc: 0.9824 - val_loss: 1.4537 - val_acc: 0.8058\nEpoch 540/1000\n - 0s - loss: 0.0493 - acc: 0.9837 - val_loss: 1.3997 - val_acc: 0.8139\nEpoch 541/1000\n - 0s - loss: 0.0507 - acc: 0.9828 - val_loss: 1.3629 - val_acc: 0.8199\nEpoch 542/1000\n - 0s - loss: 0.0550 - acc: 0.9802 - val_loss: 1.3720 - val_acc: 0.8189\nEpoch 543/1000\n - 0s - loss: 0.0456 - acc: 0.9845 - val_loss: 1.2965 - val_acc: 0.8018\nEpoch 544/1000\n - 0s - loss: 0.0648 - acc: 0.9815 - val_loss: 1.4055 - val_acc: 0.8189\nEpoch 545/1000\n - 0s - loss: 0.0435 - acc: 0.9837 - val_loss: 1.3531 - val_acc: 0.8159\nEpoch 546/1000\n - 0s - loss: 0.0425 - acc: 0.9854 - val_loss: 1.3999 - val_acc: 0.8149\nEpoch 547/1000\n - 0s - loss: 0.0523 - acc: 0.9815 - val_loss: 1.5102 - val_acc: 0.8109\nEpoch 548/1000\n - 0s - loss: 0.0602 - acc: 0.9798 - val_loss: 1.3711 - val_acc: 0.8169\nEpoch 549/1000\n - 0s - loss: 0.0386 - acc: 0.9867 - val_loss: 1.4702 - val_acc: 0.8219\nEpoch 550/1000\n - 0s - loss: 0.0446 - acc: 0.9841 - val_loss: 1.5232 - val_acc: 0.8109\nEpoch 551/1000\n - 0s - loss: 0.0634 - acc: 0.9828 - val_loss: 1.3702 - val_acc: 0.8169\nEpoch 552/1000\n - 0s - loss: 0.0439 - acc: 0.9841 - val_loss: 1.2949 - val_acc: 0.8159\nEpoch 553/1000\n - 0s - loss: 0.0485 - acc: 0.9819 - val_loss: 1.5828 - val_acc: 0.8099\nEpoch 554/1000\n - 0s - loss: 0.0520 - acc: 0.9824 - val_loss: 1.4116 - val_acc: 0.8189\nEpoch 555/1000\n - 0s - loss: 0.0438 - acc: 0.9841 - val_loss: 1.4211 - val_acc: 0.8078\nEpoch 556/1000\n - 0s - loss: 0.0539 - acc: 0.9828 - val_loss: 1.2976 - val_acc: 0.8219\nEpoch 557/1000\n - 0s - loss: 0.0686 - acc: 0.9811 - val_loss: 1.2612 - val_acc: 0.8099\nEpoch 558/1000\n - 0s - loss: 0.0541 - acc: 0.9806 - val_loss: 1.3487 - val_acc: 0.8280\nEpoch 559/1000\n - 0s - loss: 0.0499 - acc: 0.9845 - val_loss: 1.4492 - val_acc: 0.8078\nEpoch 560/1000\n - 0s - loss: 0.0595 - acc: 0.9819 - val_loss: 1.5350 - val_acc: 0.8169\nEpoch 561/1000\n - 0s - loss: 0.0612 - acc: 0.9824 - val_loss: 1.5634 - val_acc: 0.8048\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"(eval_loss, eval_accuracy) = model.evaluate(validation_data, validation_labels, batch_size= batch_size, verbose=1)\n\nprint(\"Validation Accuracy: {:.4f}%\".format(eval_accuracy * 100))\nprint(\"Validation Loss: {}\".format(eval_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = test_generator.filenames\ntruth = test_generator.classes\nlabel = test_generator.class_indices\nindexlabel = dict((value, key) for key, value in label.items())\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\npreds = model.predict(test_data)\n\npredictions = [i.argmax() for i in preds]\ny_true = [i.argmax() for i in test_labels]\ncm = confusion_matrix(y_pred=predictions, y_true=y_true)\n\nprint('Test Accuracy: {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams[\"axes.grid\"] = False\nplt.rcParams.update({'font.size': 20})\n\nlabels = []\n\nlabel = test_generator.class_indices\nindexlabel = dict((value, key) for key, value in label.items())\n\nfor k,v in indexlabel.items():\n    labels.append(v)\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion Matrix')\n\n    print(cm)\n#     fig = plt.figure()\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n#     plt.title(title)\n#     plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n#     plt.savefig('plots/3.InceptionV3-2-Private-DataSet-CM.png', bbox_inches='tight', dpi = 100) \n\n\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, classes=labels, title=' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cohen_kappa_score(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\ny_pred=predictions\ny_pred_probabilities=y_pred\n\n# y_pred = np.argmax(y_pred,axis = 1) \ny_actual = y_true\n\nclassnames=[]\nfor classname in test_generator.class_indices:\n    classnames.append(classname)\n\nconfusion_mtx = confusion_matrix(y_actual, y_pred) \nprint(confusion_mtx)\ntarget_names = classnames\nprint(classification_report(y_actual, y_pred, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total=sum(sum(cm))\n\nsensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\nprint('Sensitivity : ', sensitivity )\n\nSpecificity = cm[1,1]/(cm[1,1]+cm[0,1])\nprint('Specificity : ', Specificity )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_class = model.predict(test_data, verbose=1)\n\ny_pred_class = [np.argmax(r) for r in y_pred_class]\ntest_y = [np.argmax(r) for r in test_labels]\n\n\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n\n# Precision\nprint('Precision = ', precision_score(test_y, y_pred_class, average='weighted'))\n# (None, 'micro', 'macro', 'weighted', 'samples')\n\n# Recall\nprint('Recall = ', recall_score(test_y, y_pred_class, average='weighted'))\n\n# f1_score\nprint('f1_score = ', f1_score(test_y, y_pred_class, average='weighted'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\n\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"weighted\"):\n    label_binarizer = LabelBinarizer()\n    label_binarizer.fit(y_test)\n\n    truth = label_binarizer.transform(y_test)\n    pred = label_binarizer.transform(y_pred)\n    return roc_auc_score(truth, pred, average=average)\n# roc_auc_score\nprint('roc_auc_score = ', multiclass_roc_auc_score(test_y, y_pred_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 12})\n\nimport seaborn\nplt.style.use('seaborn-white')\n\nplt.figure()\nN = epochs\nplt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\n\nplt.legend(loc=\"center right\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}