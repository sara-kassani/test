{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 12738381917162568557, name: \"/device:XLA_CPU:0\"\n device_type: \"XLA_CPU\"\n memory_limit: 17179869184\n locality {\n }\n incarnation: 8324820622361786914\n physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n device_type: \"XLA_GPU\"\n memory_limit: 17179869184\n locality {\n }\n incarnation: 9644391785520238142\n physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n device_type: \"GPU\"\n memory_limit: 15884438733\n locality {\n   bus_id: 1\n   links {\n   }\n }\n incarnation: 15196175270804532325\n physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\nfrom sklearn.metrics import log_loss\nimport sys\nimport time\nimport math\nimport os\nimport pandas as pd\nfrom keras.callbacks import EarlyStopping\nimport numpy as np\nfrom glob import glob\nimport cv2\nimport skimage\nfrom skimage.transform import resize\nfrom keras.utils.np_utils import to_categorical\nimport keras\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.models import load_model\n# import keras.callbacks as kcall\nfrom keras.optimizers import Adam, RMSprop,SGD\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\nfrom keras.applications.vgg19 import VGG19\nfrom keras.regularizers import l2, l1\n\nimport matplotlib.pyplot as plt\nfrom keras.layers import Input, concatenate\nfrom keras import optimizers, metrics, models\nfrom keras.layers import Input, Flatten, Dense\n\n%matplotlib inline","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow as tf\n\nprint(\"Keras Version\", keras.__version__)\nprint(\"tensorflow Version\", tf.__version__)\n# print(\"dim_ordering:\", K.image_dim_ordering())","execution_count":4,"outputs":[{"output_type":"stream","text":"Keras Version 2.2.4\ntensorflow Version 1.13.1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nimg_height, img_width = 600, 600\ninput_shape = (img_height, img_width, 3)\nepochs = 1000","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/aptos-multiclass-noaug/aptos_multiclass/\"))","execution_count":6,"outputs":[{"output_type":"stream","text":"['test', 'train']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/aptos-multiclass-noaug/aptos_multiclass/train/'\ntest_dir = '../input/aptos-multiclass-noaug/aptos_multiclass/test/'","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_input(x):\n    # 'RGB'->'BGR'\n    x = x[:, :, ::-1]\n    # Zero-center by imagenet mean pixel\n    x[:, :, 0] -= 103.939\n    x[:, :, 1] -= 116.779\n    x[:, :, 2] -= 123.68\n    return x","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed = np.random.seed(1142)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n#     featurewise_center=True,\n#     featurewise_std_normalization=True,\n    preprocessing_function = preprocess_input,\n    validation_split= 0.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    subset = 'training',\n    class_mode='categorical')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    subset = 'validation',\n    class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function = preprocess_input)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    class_mode='categorical')","execution_count":9,"outputs":[{"output_type":"stream","text":"Found 2657 images belonging to 5 classes.\nFound 662 images belonging to 5 classes.\nFound 343 images belonging to 5 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_train_samples = len(train_generator.filenames)\nnb_validation_samples = len(validation_generator.filenames)\nnb_test_samples = len(test_generator.filenames)\n\npredict_size_train = int(math.ceil(nb_train_samples / batch_size))\npredict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\npredict_size_test = int(math.ceil(nb_test_samples / batch_size))\n\nnum_classes = len(train_generator.class_indices)\n\nprint(\"nb_train_samples:\", nb_train_samples)\nprint(\"nb_validation_samples:\", nb_validation_samples)\nprint(\"nb_test_samples:\", nb_test_samples)\n\nprint(\"\\npredict_size_train:\", predict_size_train)\nprint(\"predict_size_validation:\", predict_size_validation)\nprint(\"predict_size_test:\", predict_size_test)\n\nprint(\"\\n num_classes:\", num_classes)","execution_count":10,"outputs":[{"output_type":"stream","text":"nb_train_samples: 2657\nnb_validation_samples: 662\nnb_test_samples: 343\n\npredict_size_train: 21\npredict_size_validation: 6\npredict_size_test: 3\n\n num_classes: 5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"extracted_features\")\nextracted_features_dir = \"extracted_features/\"\nmodel_name = \"VGG19_descriptors\"","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg19_weights =\"../input/full-keras-pretrained-no-top/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ninception_weights =\"../input/full-keras-pretrained-no-top//inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nvgg16_weights =\"../input/full-keras-pretrained-no-top/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ndenseNet201_weights =\"../input/full-keras-pretrained-no-top/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ndenseNet121_weights =\"../input/full-keras-pretrained-no-top/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nresenet50_weights =\"../input/full-keras-pretrained-no-top/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ninception_resnet_v2_weights =\"../input/full-keras-pretrained-no-top/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nnasnet_weights =\"../input/full-keras-pretrained-no-top/nasnet_large_no_top.h5\"\nnasnet_mobile_weights =\"../input/full-keras-pretrained-no-top/nasnet_mobile_no_top.h5\"\nmobilenet_weights =\"../input/full-keras-pretrained-no-top/mobilenet_1_0_224_tf_no_top.h5\"\nxception_weights = \"../input/full-keras-pretrained-no-top/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.applications import DenseNet201\nfrom keras.applications import DenseNet121\nfrom keras.applications import ResNet50\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications import NASNetLarge, NASNetMobile\nfrom keras.applications import MobileNet","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor = Input(shape = input_shape)  \n\nbase_model1=DenseNet121(weights=denseNet121_weights, include_top=False, pooling = \"avg\")\n# base_model2=Xception(input_shape= input_shape,weights=xception_weights, include_top=False, input_tensor=input_tensor)\n\n# x1 = base_model1.output\n# x1 = GlobalAveragePooling2D()(x1)\n\n# x2 = base_model2.output\n# x2 = GlobalAveragePooling2D()(x2)\n\n# merge = concatenate([x1, x2])\n# predictions = Dense(num_classes, activation='softmax')(merge)\n\n# model = Model(inputs=input_tensor,outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i, layer in enumerate(model.layers):\n#     print(i, layer.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_final_model = base_model1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_train = bottleneck_final_model.predict_generator(train_generator, predict_size_train, max_q_size=1, pickle_safe=False)\nnp.save(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_validation = bottleneck_final_model.predict_generator(validation_generator, predict_size_validation)\nnp.save(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_test = bottleneck_final_model.predict_generator(test_generator, predict_size_test)\nnp.save(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import tensorflow as tf\n# from keras.backend.tensorflow_backend import get_session\n# from keras.backend.tensorflow_backend import clear_session\n# from keras.backend.tensorflow_backend import set_session\n\n# def reset_keras_tf_session():\n#     \"\"\"\n#     this function clears the gpu memory and set the \n#     tf session to not use the whole gpu\n#     \"\"\"\n#     sess = get_session()\n#     clear_session()\n#     sess.close()\n#     sess = get_session()\n\n# #     config = tf.ConfigProto()\n# #     config.gpu_options.allow_growth = True\n# #     set_session(tf.Session(config=config))\n\n# reset_keras_tf_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = np.load(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy')\nvalidation_data = np.load(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy')\ntest_data = np.load(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy')\n\ntrain_labels = train_generator.classes\ntrain_labels = to_categorical(train_labels, num_classes=num_classes)\n\nvalidation_labels = validation_generator.classes\nvalidation_labels = to_categorical(validation_labels, num_classes=num_classes)\n\ntest_labels = test_generator.classes\ntest_labels = to_categorical(test_labels, num_classes=num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"space = {\n         'lr': hp.choice('lr',[0.1, 0.01, 0.001, 0.0001, 0.00001,0.000001, 0.0000001]),\n#          'dropout': hp.choice('dropout', [0.4, 0.5, 0.6, 0.7]),\n#          'batch_size': hp.choice('batch_size', [64]),\n#          'epochs': hp.choice('epochs', [15, 20, 25, 30, 50]),\n#          'optimizer': hp.choice('optimizer',['sgd','adam','rmsprop']),\n#          'optimizer': hp.choice('optimizer',['rmsprop']),\n#          'optimizer': hp.choice('optimizer',['adam']),\n         'beta_1':hp.choice('beta_1',[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8, 0.9]),\n         'beta_2':hp.choice('beta_2',[0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.999,0.99,0.995]),\n#          'momentum':hp.choice('momentum',[0.3,0.5,0.7,0.9,1]),\n#          'amsgrad':hp.choice('amsgrad',[False,True]),\n#          'nesterov':hp.choice('nesterov',[False,True]),\n#          'rho':hp.choice('rho',[0.4,0.5,0.6,0.7,0.8,0.9,1]),\n        'hidden1':hp.choice('hidden1',[4096,2048,1024,512,256]),\n        'hidden2':hp.choice('hidden2',[2048,1024,512,256,128,]),\n        'bias_reg': hp.choice('bias_reg',[0.1, 0.01, 0.001, 0.0001, 0.00001,0.000001, 0.0000001]),\n        'act_reg': hp.choice('act_reg',[0.1, 0.01, 0.001, 0.0001, 0.00001,0.000001, 0.0000001]),\n        'ker_reg': hp.choice('ker_reg',[0.1, 0.01, 0.001, 0.0001, 0.00001,0.000001, 0.0000001]),\n        'activation_function':hp.choice('activation_function',[\"relu\",\"elu\",\"selu\",\"softplus\",\"tanh\",])\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ndef f_nn(params):   \n    print ('Parameters testing: ', params)\n#     dropout_rate = 0.5\n    adam_opt=Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params['beta_2'])\n#     sgd=SGD(lr=params[\"lr\"], momentum=params['momentum'], decay=0.0, nesterov=params['nesterov'])\n#     rmsprop=RMSprop(lr=params[\"lr\"], rho=params['rho'], epsilon=None, decay=0.0)\n\n    model = Sequential()\n    # model.add(Flatten(input_shape=train_data.shape[1:]))\n    model.add(Dense(params[\"hidden1\"], activation=params[\"activation_function\"], kernel_regularizer=l2(params[\"ker_reg\"]), bias_regularizer=l2(params[\"bias_reg\"]), activity_regularizer=l1(params[\"act_reg\"])))\n#     model.add(Dropout(0.5))\n\n    model.add(Dense(params[\"hidden2\"], activation=params[\"activation_function\"], kernel_regularizer=l2(params[\"ker_reg\"]), bias_regularizer=l2(params[\"bias_reg\"]), activity_regularizer=l1(params[\"act_reg\"])))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(num_classes, activation=\"softmax\"))\n\n    model.compile(optimizer=adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    history = model.fit(train_data, train_labels,\n                        epochs=epochs,\n                        batch_size=batch_size,\n                        validation_data=(validation_data, validation_labels),\n                        verbose= 2,\n                        callbacks=get_callbacks(params))\n\n    (eval_loss, eval_accuracy) = model.evaluate(validation_data, validation_labels, batch_size= batch_size, verbose=1)\n\n    print(\"Validation Accuracy: {:.4f}%\".format(eval_accuracy * 100))\n    print(\"Validation Loss: {}\".format(eval_loss))\n    \n    filename = test_generator.filenames\n    truth = test_generator.classes\n    label = test_generator.class_indices\n    indexlabel = dict((value, key) for key, value in label.items())\n\n    preds = model.predict(test_data)\n\n    predictions = [i.argmax() for i in preds]\n    y_true = [i.argmax() for i in test_labels]\n#     cm = confusion_matrix(y_pred=predictions, y_true=y_true)\n\n    print('Test Accuracy: {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))\n\n    print(\"*_*\" * 50)\n#     best_epoch = np.argmax(history.history['val_acc'])\n#     best_val_acc = np.max(history.history['val_acc'])\n#     print('Epoch {} - val acc: {}'.format(best_epoch, best_val_acc))\n    sys.stdout.flush() \n    \n    return {'loss': eval_loss, 'status': STATUS_OK, 'model': model}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_callbacks(params):\n    callbacks =[EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    return callbacks","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"trials = Trials()\nbest = fmin(f_nn, space, algo=tpe.suggest, max_evals = 300, trials=trials)\nprint(best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}