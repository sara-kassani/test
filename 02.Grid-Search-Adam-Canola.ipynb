{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8534838361088915575, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9214062756\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15306329601180315333\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\n",
    "from sklearn.metrics import log_loss\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import keras.callbacks as kcall\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, concatenate\n",
    "from keras import optimizers, metrics, models\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_classes = 2\n",
    "batch_size = 64\n",
    "img_height, img_width = 224, 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "# epochs = 50\n",
    "\n",
    "nb_train_samples = 787\n",
    "nb_validation_samples = 262\n",
    "nb_test_samples = 317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train/'\n",
    "test_dir = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 787 images belonging to 2 classes.\n",
      "Found 262 images belonging to 2 classes.\n",
      "Found 317 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    validation_split=0.25)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    subset=\"training\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    subset=\"validation\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19_model():\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, pooling='avg')\n",
    "    x = base_model.output\n",
    "    # x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    prediction = Dense(output_classes, activation=tf.nn.softmax)(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input,outputs=prediction)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "         'lr': hp.choice('lr',[1.0, 0.001, 0.0001, 0.00001,0.000001]),\n",
    "#          'dropout': hp.choice('dropout', [0.4, 0.5, 0.6, 0.7]),\n",
    "#          'batch_size': hp.choice('batch_size', [64]),\n",
    "#          'epochs': hp.choice('epochs', [15, 20, 25, 30, 50]),\n",
    "#          'optimizer': hp.choice('optimizer',['sgd','adam','rmsprop']),\n",
    "#          'optimizer': hp.choice('optimizer',['rmsprop']),\n",
    "#          'optimizer': hp.choice('optimizer',['adam']),\n",
    "         'beta_1':hp.choice('beta_1',[0.3,0.4,0.5,0.6,0.7,0.8]),\n",
    "         'beta_2':hp.choice('beta_2',[0.99,0.995,0.7,0.8,0.9,0.999]),\n",
    "#          'momentum':hp.choice('momentum',[0.3,0.5,0.7,0.9,1]),\n",
    "         'amsgrad':hp.choice('amsgrad',[False,True]),\n",
    "#          'nesterov':hp.choice('nesterov',[False,True]),\n",
    "#          'rho':hp.choice('rho',[0.4,0.5,0.6,0.7,0.8,0.9,1]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_nn(params):   \n",
    "    print ('Parameters testing: ', params)\n",
    "#     batch_size=params['batch_size']\n",
    "\n",
    "#     random_seed = np.random.seed(1132)\n",
    "\n",
    "#     train_datagen = ImageDataGenerator(\n",
    "#         rescale=1. / 255,\n",
    "#         featurewise_center=True,\n",
    "#         featurewise_std_normalization=True)\n",
    "\n",
    "#     test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#     train_generator = train_datagen.flow_from_directory(\n",
    "#         train_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = True,\n",
    "#         seed = random_seed,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#     validation_generator = train_datagen.flow_from_directory(\n",
    "#         validation_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = True,\n",
    "#         seed = random_seed,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#     test_generator = test_datagen.flow_from_directory(\n",
    "#         test_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = False,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "   \n",
    "    adam_opt = Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params['beta_2'], epsilon=None, decay=0.0, amsgrad=params['amsgrad'])\n",
    "#     sgd=SGD(lr=params[\"lr\"], momentum=params['momentum'], decay=0.0, nesterov=params['nesterov'])\n",
    "#     rmsprop=RMSprop(lr=params[\"lr\"], rho=params['rho'], epsilon=None, decay=0.0)\n",
    "\n",
    "    model = vgg19_model()\n",
    "    \n",
    "    model.compile(optimizer = adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = nb_train_samples // batch_size,\n",
    "      epochs = 15,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps = nb_validation_samples // batch_size,\n",
    "      verbose = 1)\n",
    "    \n",
    "    score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "    print ('Validation Score: ', score[0])\n",
    "    print ('Validation Accuracy: ',score[1])\n",
    "    \n",
    "    filename = test_generator.filenames\n",
    "    truth = test_generator.classes\n",
    "    label = test_generator.class_indices\n",
    "    indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "    predicts = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "    predict_class = np.argmax(predicts, axis=1)\n",
    "    errors = np.where(predict_class != truth)[0]\n",
    "    print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n",
    "    th= 0.3\n",
    "    acc = accuracy_score(truth, predict_class > th)\n",
    "    print(\"Accuracy: {:.4f}\".format(acc*100))\n",
    "    print(\"*_*\" * 50)\n",
    "    \n",
    "#     best_epoch = np.argmax(history.history['val_acc'])\n",
    "#     best_val_acc = np.max(history.history['val_acc'])\n",
    "#     print('Epoch {} - val acc: {}'.format(best_epoch, best_val_acc))\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "    return {'loss': score[0], 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters testing:  {'lr': 1e-06, 'beta_1': 0.4, 'amsgrad': True, 'beta_2': 0.999}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.8969 - acc: 0.6687 - val_loss: 0.4794 - val_acc: 0.9258\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 7s 613ms/step - loss: 0.7634 - acc: 0.7215 - val_loss: 0.4414 - val_acc: 0.9495\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 602ms/step - loss: 0.6786 - acc: 0.7573 - val_loss: 0.3916 - val_acc: 0.9747\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 607ms/step - loss: 0.6302 - acc: 0.7869 - val_loss: 0.4091 - val_acc: 0.9545\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 7s 618ms/step - loss: 0.6506 - acc: 0.7786 - val_loss: 0.3892 - val_acc: 0.9596\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 7s 575ms/step - loss: 0.5580 - acc: 0.8187 - val_loss: 0.3605 - val_acc: 0.9648\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.5376 - acc: 0.8225 - val_loss: 0.3376 - val_acc: 0.9747\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 8s 636ms/step - loss: 0.5120 - acc: 0.8646 - val_loss: 0.3402 - val_acc: 0.9545\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 607ms/step - loss: 0.4834 - acc: 0.8641 - val_loss: 0.3189 - val_acc: 0.9747\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 594ms/step - loss: 0.4985 - acc: 0.8630 - val_loss: 0.3159 - val_acc: 0.9545\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 602ms/step - loss: 0.4585 - acc: 0.8844 - val_loss: 0.3066 - val_acc: 0.9609\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 611ms/step - loss: 0.4537 - acc: 0.8824 - val_loss: 0.3094 - val_acc: 0.9545\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 611ms/step - loss: 0.4105 - acc: 0.9137 - val_loss: 0.2956 - val_acc: 0.9596\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 604ms/step - loss: 0.4150 - acc: 0.9182 - val_loss: 0.2720 - val_acc: 0.9697\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 591ms/step - loss: 0.3997 - acc: 0.9202 - val_loss: 0.2764 - val_acc: 0.9646\n",
      "Validation Score:  0.28221486403059415\n",
      "Validation Accuracy:  0.9618320609777028\n",
      "5/4 [==============================] - 2s 488ms/step\n",
      "No of errors = 9/317\n",
      "Accuracy: 97.1609\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 0.0001, 'beta_1': 0.3, 'amsgrad': True, 'beta_2': 0.7}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6983 - acc: 0.7473 - val_loss: 0.9680 - val_acc: 0.6680\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 7s 609ms/step - loss: 0.3287 - acc: 0.9437 - val_loss: 0.9938 - val_acc: 0.4444\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 608ms/step - loss: 0.2299 - acc: 0.9854 - val_loss: 0.4733 - val_acc: 0.8737\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.2307 - acc: 0.9765 - val_loss: 0.1771 - val_acc: 1.0000\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 7s 625ms/step - loss: 0.2060 - acc: 0.9883 - val_loss: 0.1748 - val_acc: 1.0000\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 7s 576ms/step - loss: 0.2226 - acc: 0.9785 - val_loss: 0.1767 - val_acc: 1.0000\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 8s 640ms/step - loss: 0.2141 - acc: 0.9870 - val_loss: 0.7247 - val_acc: 0.6818\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 7s 617ms/step - loss: 0.2000 - acc: 0.9838 - val_loss: 0.1748 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.1975 - acc: 0.9908 - val_loss: 0.1963 - val_acc: 0.9798\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 593ms/step - loss: 0.1891 - acc: 0.9945 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 608ms/step - loss: 0.1957 - acc: 0.9922 - val_loss: 0.1965 - val_acc: 0.9883\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 614ms/step - loss: 0.1876 - acc: 0.9935 - val_loss: 1.3363 - val_acc: 0.7475\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 614ms/step - loss: 0.1843 - acc: 0.9935 - val_loss: 0.1714 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 613ms/step - loss: 0.1874 - acc: 0.9945 - val_loss: 0.3401 - val_acc: 0.9141\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 595ms/step - loss: 0.2199 - acc: 0.9854 - val_loss: 1.2842 - val_acc: 0.6919\n",
      "Validation Score:  1.2461560750735625\n",
      "Validation Accuracy:  0.7022900762903781\n",
      "5/4 [==============================] - 1s 284ms/step\n",
      "No of errors = 82/317\n",
      "Accuracy: 74.1325\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 1e-06, 'beta_1': 0.8, 'amsgrad': True, 'beta_2': 0.8}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 14s 1s/step - loss: 1.0483 - acc: 0.5856 - val_loss: 0.5614 - val_acc: 0.9062\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 8s 651ms/step - loss: 0.9724 - acc: 0.6094 - val_loss: 0.4811 - val_acc: 0.9394\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.8621 - acc: 0.6707 - val_loss: 0.4360 - val_acc: 0.9444\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 589ms/step - loss: 0.8982 - acc: 0.6892 - val_loss: 0.3747 - val_acc: 0.9646\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 7s 597ms/step - loss: 0.7366 - acc: 0.7293 - val_loss: 0.3869 - val_acc: 0.9545\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 8s 637ms/step - loss: 0.6905 - acc: 0.7513 - val_loss: 0.3656 - val_acc: 0.9570\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 7s 611ms/step - loss: 0.6732 - acc: 0.7754 - val_loss: 0.3539 - val_acc: 0.9596\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 7s 614ms/step - loss: 0.6983 - acc: 0.7415 - val_loss: 0.3513 - val_acc: 0.9495\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 584ms/step - loss: 0.6682 - acc: 0.7709 - val_loss: 0.3460 - val_acc: 0.9394\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 621ms/step - loss: 0.6079 - acc: 0.8047 - val_loss: 0.3206 - val_acc: 0.9646\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 609ms/step - loss: 0.6039 - acc: 0.8057 - val_loss: 0.3208 - val_acc: 0.9531\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 612ms/step - loss: 0.5397 - acc: 0.8452 - val_loss: 0.3131 - val_acc: 0.9545\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 617ms/step - loss: 0.5903 - acc: 0.8011 - val_loss: 0.3044 - val_acc: 0.9596\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 619ms/step - loss: 0.5633 - acc: 0.8181 - val_loss: 0.3070 - val_acc: 0.9596\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 599ms/step - loss: 0.5385 - acc: 0.8327 - val_loss: 0.3045 - val_acc: 0.9495\n",
      "Validation Score:  0.30072792598991904\n",
      "Validation Accuracy:  0.9541984731914432\n",
      "5/4 [==============================] - 2s 303ms/step\n",
      "No of errors = 12/317\n",
      "Accuracy: 96.2145\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 1.0, 'beta_1': 0.3, 'amsgrad': False, 'beta_2': 0.995}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 12s 1s/step - loss: 90.3928 - acc: 0.6417 - val_loss: 26.7436 - val_acc: 0.6523\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 7s 600ms/step - loss: 16.2941 - acc: 0.6469 - val_loss: 12.4441 - val_acc: 0.6616\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 592ms/step - loss: 10.6382 - acc: 0.6585 - val_loss: 11.6266 - val_acc: 0.6566\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 590ms/step - loss: 8.8130 - acc: 0.6528 - val_loss: 8.9129 - val_acc: 0.6313\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 7s 580ms/step - loss: 8.5139 - acc: 0.6410 - val_loss: 8.1436 - val_acc: 0.6818\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 7s 588ms/step - loss: 8.7600 - acc: 0.6929 - val_loss: 8.1303 - val_acc: 0.6562\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 7s 595ms/step - loss: 8.7314 - acc: 0.6665 - val_loss: 10.1967 - val_acc: 0.6566\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 7s 623ms/step - loss: 9.2136 - acc: 0.6250 - val_loss: 9.9214 - val_acc: 0.6364\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 562ms/step - loss: 9.4637 - acc: 0.6832 - val_loss: 7.8940 - val_acc: 0.6919\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 612ms/step - loss: 9.0619 - acc: 0.6406 - val_loss: 8.1732 - val_acc: 0.6414\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 590ms/step - loss: 9.7631 - acc: 0.6678 - val_loss: 9.1429 - val_acc: 0.6523\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 606ms/step - loss: 11.2060 - acc: 0.6655 - val_loss: 8.2328 - val_acc: 0.6768\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 600ms/step - loss: 9.0635 - acc: 0.6504 - val_loss: 9.5050 - val_acc: 0.6616\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 599ms/step - loss: 9.0999 - acc: 0.6506 - val_loss: 9.5917 - val_acc: 0.6566\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 579ms/step - loss: 11.7788 - acc: 0.6645 - val_loss: 10.0893 - val_acc: 0.6364\n",
      "Validation Score:  9.764889740033913\n",
      "Validation Accuracy:  0.6564885498685691\n",
      "5/4 [==============================] - 2s 315ms/step\n",
      "No of errors = 108/317\n",
      "Accuracy: 65.9306\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 1e-05, 'beta_1': 0.3, 'amsgrad': False, 'beta_2': 0.7}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 13s 1s/step - loss: 0.6494 - acc: 0.7612 - val_loss: 0.2942 - val_acc: 0.9766\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.4518 - acc: 0.8702 - val_loss: 0.2917 - val_acc: 0.9596\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 608ms/step - loss: 0.3309 - acc: 0.9385 - val_loss: 0.2500 - val_acc: 0.9697\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 610ms/step - loss: 0.3003 - acc: 0.9581 - val_loss: 0.2547 - val_acc: 0.9596\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 8s 628ms/step - loss: 0.2454 - acc: 0.9740 - val_loss: 0.2116 - val_acc: 0.9848\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 7s 605ms/step - loss: 0.2485 - acc: 0.9765 - val_loss: 0.2057 - val_acc: 0.9844\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 7s 614ms/step - loss: 0.2158 - acc: 0.9882 - val_loss: 0.1877 - val_acc: 0.9899\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 7s 616ms/step - loss: 0.2096 - acc: 0.9882 - val_loss: 0.1915 - val_acc: 0.9848\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.2112 - acc: 0.9869 - val_loss: 0.1820 - val_acc: 0.9949\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 596ms/step - loss: 0.1911 - acc: 0.9935 - val_loss: 0.1797 - val_acc: 0.9949\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 606ms/step - loss: 0.2088 - acc: 0.9880 - val_loss: 0.1951 - val_acc: 0.9844\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 608ms/step - loss: 0.1930 - acc: 0.9908 - val_loss: 0.3218 - val_acc: 0.9293\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 611ms/step - loss: 0.2042 - acc: 0.9851 - val_loss: 0.2049 - val_acc: 0.9798\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 609ms/step - loss: 0.1835 - acc: 0.9948 - val_loss: 0.1743 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 593ms/step - loss: 0.1880 - acc: 0.9919 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Validation Score:  0.17487995723504146\n",
      "Validation Accuracy:  0.9961832061068703\n",
      "5/4 [==============================] - 2s 356ms/step\n",
      "No of errors = 2/317\n",
      "Accuracy: 99.3691\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 1e-05, 'beta_1': 0.3, 'amsgrad': False, 'beta_2': 0.999}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 13s 1s/step - loss: 1.1093 - acc: 0.5924 - val_loss: 0.5216 - val_acc: 0.8984\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 7s 586ms/step - loss: 0.6274 - acc: 0.7983 - val_loss: 0.4018 - val_acc: 0.9798\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 614ms/step - loss: 0.3993 - acc: 0.9173 - val_loss: 0.3523 - val_acc: 0.9899\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 617ms/step - loss: 0.3038 - acc: 0.9647 - val_loss: 0.2637 - val_acc: 0.9949\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 8s 628ms/step - loss: 0.3186 - acc: 0.9570 - val_loss: 0.2518 - val_acc: 0.9899\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 7s 611ms/step - loss: 0.2652 - acc: 0.9697 - val_loss: 0.2258 - val_acc: 1.0000\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 7s 580ms/step - loss: 0.2673 - acc: 0.9759 - val_loss: 0.2176 - val_acc: 1.0000\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 8s 642ms/step - loss: 0.2274 - acc: 0.9883 - val_loss: 0.1915 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.2520 - acc: 0.9736 - val_loss: 0.2047 - val_acc: 0.9899\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 595ms/step - loss: 0.2155 - acc: 0.9893 - val_loss: 0.1812 - val_acc: 1.0000\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 609ms/step - loss: 0.2135 - acc: 0.9935 - val_loss: 0.1811 - val_acc: 1.0000\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 610ms/step - loss: 0.2150 - acc: 0.9882 - val_loss: 0.1831 - val_acc: 0.9949\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.2036 - acc: 0.9948 - val_loss: 0.1806 - val_acc: 0.9949\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.2081 - acc: 0.9906 - val_loss: 0.1770 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 593ms/step - loss: 0.2138 - acc: 0.9895 - val_loss: 0.1793 - val_acc: 1.0000\n",
      "Validation Score:  0.17817819849907898\n",
      "Validation Accuracy:  1.0\n",
      "5/4 [==============================] - 2s 358ms/step\n",
      "No of errors = 6/317\n",
      "Accuracy: 98.1073\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 1.0, 'beta_1': 0.8, 'amsgrad': False, 'beta_2': 0.995}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 13s 1s/step - loss: nan - acc: 0.6340 - val_loss: nan - val_acc: 0.6602\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 7s 595ms/step - loss: nan - acc: 0.6676 - val_loss: nan - val_acc: 0.6313\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 622ms/step - loss: nan - acc: 0.6497 - val_loss: nan - val_acc: 0.6717\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 571ms/step - loss: nan - acc: 0.6749 - val_loss: nan - val_acc: 0.6616\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 7s 579ms/step - loss: nan - acc: 0.6323 - val_loss: nan - val_acc: 0.6566\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 7s 619ms/step - loss: nan - acc: 0.6602 - val_loss: nan - val_acc: 0.6602\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 7s 571ms/step - loss: nan - acc: 0.6567 - val_loss: nan - val_acc: 0.6566\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 7s 622ms/step - loss: nan - acc: 0.6628 - val_loss: nan - val_acc: 0.6414\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 603ms/step - loss: nan - acc: 0.6491 - val_loss: nan - val_acc: 0.6566\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 580ms/step - loss: nan - acc: 0.6652 - val_loss: nan - val_acc: 0.6667\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 588ms/step - loss: nan - acc: 0.6462 - val_loss: nan - val_acc: 0.6562\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 591ms/step - loss: nan - acc: 0.6772 - val_loss: nan - val_acc: 0.6818\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 603ms/step - loss: nan - acc: 0.6469 - val_loss: nan - val_acc: 0.6162\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 598ms/step - loss: nan - acc: 0.6598 - val_loss: nan - val_acc: 0.6768\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 578ms/step - loss: nan - acc: 0.6589 - val_loss: nan - val_acc: 0.6515\n",
      "Validation Score:  nan\n",
      "Validation Accuracy:  0.6564885495728209\n",
      "5/4 [==============================] - 2s 372ms/step\n",
      "No of errors = 108/317\n",
      "Accuracy: 65.9306\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 0.0001, 'beta_1': 0.5, 'amsgrad': True, 'beta_2': 0.7}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.5367 - acc: 0.8333 - val_loss: 0.4256 - val_acc: 0.9062\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 7s 588ms/step - loss: 0.2453 - acc: 0.9761 - val_loss: 0.6300 - val_acc: 0.7879\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 614ms/step - loss: 0.2247 - acc: 0.9804 - val_loss: 0.1703 - val_acc: 1.0000\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.2146 - acc: 0.9854 - val_loss: 0.2164 - val_acc: 0.9848\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 7s 596ms/step - loss: 0.2110 - acc: 0.9856 - val_loss: 0.1719 - val_acc: 1.0000\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 8s 635ms/step - loss: 0.1960 - acc: 0.9922 - val_loss: 0.2051 - val_acc: 0.9805\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 7s 621ms/step - loss: 0.1858 - acc: 0.9948 - val_loss: 0.2034 - val_acc: 0.9798\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 7s 620ms/step - loss: 0.2007 - acc: 0.9906 - val_loss: 0.2867 - val_acc: 0.9596\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 613ms/step - loss: 0.1759 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 1.0000\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 563ms/step - loss: 0.1788 - acc: 0.9974 - val_loss: 0.1863 - val_acc: 0.9949\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 8s 638ms/step - loss: 0.1722 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9805\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 618ms/step - loss: 0.1701 - acc: 1.0000 - val_loss: 0.1863 - val_acc: 0.9899\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 606ms/step - loss: 0.2070 - acc: 0.9880 - val_loss: 1.2492 - val_acc: 0.6869\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 8s 640ms/step - loss: 0.1872 - acc: 0.9935 - val_loss: 0.1964 - val_acc: 0.9899\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 567ms/step - loss: 0.1722 - acc: 0.9987 - val_loss: 0.1707 - val_acc: 1.0000\n",
      "Validation Score:  0.16988920923180253\n",
      "Validation Accuracy:  1.0\n",
      "5/4 [==============================] - 2s 398ms/step\n",
      "No of errors = 0/317\n",
      "Accuracy: 100.0000\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 0.0001, 'beta_1': 0.4, 'amsgrad': True, 'beta_2': 0.8}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.6074 - acc: 0.8046 - val_loss: 0.3175 - val_acc: 0.9688\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 7s 609ms/step - loss: 0.2837 - acc: 0.9540 - val_loss: 1.5860 - val_acc: 0.3939\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.2293 - acc: 0.9801 - val_loss: 0.2445 - val_acc: 0.9646\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 615ms/step - loss: 0.2473 - acc: 0.9705 - val_loss: 0.1709 - val_acc: 1.0000\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 8s 629ms/step - loss: 0.2310 - acc: 0.9805 - val_loss: 0.7932 - val_acc: 0.7020\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 7s 612ms/step - loss: 0.1940 - acc: 0.9961 - val_loss: 1.1490 - val_acc: 0.6523\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 8s 631ms/step - loss: 0.1965 - acc: 0.9935 - val_loss: 0.1706 - val_acc: 1.0000\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 7s 619ms/step - loss: 0.1881 - acc: 0.9935 - val_loss: 0.1704 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 7s 622ms/step - loss: 0.1861 - acc: 0.9935 - val_loss: 0.1776 - val_acc: 0.9949\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 564ms/step - loss: 0.2016 - acc: 0.9866 - val_loss: 1.6833 - val_acc: 0.7020\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 8s 635ms/step - loss: 0.1894 - acc: 0.9935 - val_loss: 0.2568 - val_acc: 0.9609\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 609ms/step - loss: 0.1755 - acc: 0.9974 - val_loss: 0.1741 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 618ms/step - loss: 0.1750 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 613ms/step - loss: 0.1723 - acc: 1.0000 - val_loss: 0.1883 - val_acc: 0.9899\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 625ms/step - loss: 0.1728 - acc: 0.9987 - val_loss: 0.3988 - val_acc: 0.9242\n",
      "Validation Score:  0.4097112662692106\n",
      "Validation Accuracy:  0.9198473280622759\n",
      "5/4 [==============================] - 2s 415ms/step\n",
      "No of errors = 15/317\n",
      "Accuracy: 95.2681\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 0.0001, 'beta_1': 0.4, 'amsgrad': False, 'beta_2': 0.99}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 15s 1s/step - loss: 0.6507 - acc: 0.7939 - val_loss: 0.1825 - val_acc: 0.9961\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 8s 654ms/step - loss: 0.2930 - acc: 0.9544 - val_loss: 0.2141 - val_acc: 0.9697\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 591ms/step - loss: 0.2618 - acc: 0.9722 - val_loss: 7.6390 - val_acc: 0.3182\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 7s 622ms/step - loss: 0.2510 - acc: 0.9723 - val_loss: 0.4987 - val_acc: 0.8434\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 7s 598ms/step - loss: 0.2060 - acc: 0.9867 - val_loss: 10.9721 - val_acc: 0.3283\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 7s 610ms/step - loss: 0.2292 - acc: 0.9788 - val_loss: 0.1943 - val_acc: 1.0000\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 7s 620ms/step - loss: 0.1923 - acc: 0.9935 - val_loss: 0.1722 - val_acc: 1.0000\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 7s 610ms/step - loss: 0.1870 - acc: 0.9961 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 8s 650ms/step - loss: 0.1765 - acc: 0.9961 - val_loss: 0.1704 - val_acc: 1.0000\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 598ms/step - loss: 0.1752 - acc: 0.9987 - val_loss: 0.2879 - val_acc: 0.9444\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 604ms/step - loss: 0.2025 - acc: 0.9854 - val_loss: 2.3287 - val_acc: 0.5000\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 7s 616ms/step - loss: 0.2271 - acc: 0.9817 - val_loss: 0.1769 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 7s 616ms/step - loss: 0.1812 - acc: 0.9945 - val_loss: 0.2630 - val_acc: 0.9646\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 7s 614ms/step - loss: 0.1845 - acc: 0.9948 - val_loss: 0.3876 - val_acc: 0.9091\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 7s 599ms/step - loss: 0.1979 - acc: 0.9843 - val_loss: 0.1642 - val_acc: 1.0000\n",
      "Validation Score:  0.16424147965571353\n",
      "Validation Accuracy:  1.0\n",
      "5/4 [==============================] - 2s 423ms/step\n",
      "No of errors = 5/317\n",
      "Accuracy: 98.4227\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 0.0001, 'beta_1': 0.6, 'amsgrad': True, 'beta_2': 0.999}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 18s 1s/step - loss: 0.5947 - acc: 0.8209 - val_loss: 4.0383 - val_acc: 0.3438\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 8s 667ms/step - loss: 0.2837 - acc: 0.9609 - val_loss: 7.8900 - val_acc: 0.3081\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 7s 613ms/step - loss: 0.2748 - acc: 0.9638 - val_loss: 8.8968 - val_acc: 0.3838\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 8s 663ms/step - loss: 0.2163 - acc: 0.9857 - val_loss: 3.2791 - val_acc: 0.3889\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 7s 613ms/step - loss: 0.2068 - acc: 0.9856 - val_loss: 0.2310 - val_acc: 0.9747\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 7s 600ms/step - loss: 0.1949 - acc: 0.9895 - val_loss: 1.8050 - val_acc: 0.5312\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 8s 667ms/step - loss: 0.2005 - acc: 0.9922 - val_loss: 0.2015 - val_acc: 0.9949\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 8s 631ms/step - loss: 0.1857 - acc: 0.9922 - val_loss: 0.1719 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 8s 631ms/step - loss: 0.2067 - acc: 0.9869 - val_loss: 1.7197 - val_acc: 0.6717\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 7s 614ms/step - loss: 0.2152 - acc: 0.9843 - val_loss: 0.2758 - val_acc: 0.9596\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 7s 621ms/step - loss: 0.1918 - acc: 0.9893 - val_loss: 0.1969 - val_acc: 0.9922\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 8s 642ms/step - loss: 0.1694 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 8s 633ms/step - loss: 0.1702 - acc: 0.9987 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 8s 631ms/step - loss: 0.1731 - acc: 0.9974 - val_loss: 0.1685 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 8s 646ms/step - loss: 0.1726 - acc: 0.9961 - val_loss: 0.2134 - val_acc: 0.9949\n",
      "Validation Score:  0.20571122285518936\n",
      "Validation Accuracy:  0.9961832061068703\n",
      "5/4 [==============================] - 2s 451ms/step\n",
      "No of errors = 73/317\n",
      "Accuracy: 76.9716\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'lr': 1e-05, 'beta_1': 0.4, 'amsgrad': True, 'beta_2': 0.995}\n",
      "Epoch 1/15\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7473 - acc: 0.7191 - val_loss: 0.2866 - val_acc: 0.9805\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 10s 814ms/step - loss: 0.4831 - acc: 0.8628 - val_loss: 0.2606 - val_acc: 0.9697\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 10s 795ms/step - loss: 0.3633 - acc: 0.9411 - val_loss: 0.2276 - val_acc: 0.9848\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 10s 830ms/step - loss: 0.3133 - acc: 0.9555 - val_loss: 0.2111 - val_acc: 0.9798\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 9s 776ms/step - loss: 0.2739 - acc: 0.9642 - val_loss: 0.2088 - val_acc: 0.9848\n",
      "Epoch 6/15\n",
      " 4/12 [=========>....................] - ETA: 6s - loss: 0.2778 - acc: 0.9805"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_11/Adam/gradients/block1_conv2_11/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@train...propFilter\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_11/Adam/gradients/block1_conv2_11/convolution_grad/ShapeN, block1_conv2_11/kernel/read, training_11/Adam/gradients/block1_conv2_11/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c9777c3a16cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m         )\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[0;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-8d0f267aa98e>\u001b[0m in \u001b[0;36mf_nn\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     50\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_validation_samples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m       verbose = 1)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[1;32m-> 1454\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_11/Adam/gradients/block1_conv2_11/convolution_grad/Conv2DBackpropInput = Conv2DBackpropInput[T=DT_FLOAT, _class=[\"loc:@train...propFilter\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_11/Adam/gradients/block1_conv2_11/convolution_grad/ShapeN, block1_conv2_11/kernel/read, training_11/Adam/gradients/block1_conv2_11/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
