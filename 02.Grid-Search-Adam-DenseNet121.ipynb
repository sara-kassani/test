{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2592658019406236032, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10968950375\n",
       " locality {\n",
       "   bus_id: 2\n",
       " }\n",
       " incarnation: 14912489397557601197\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1\", name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10968950375\n",
       " locality {\n",
       "   bus_id: 2\n",
       " }\n",
       " incarnation: 8633491846942947616\n",
       " physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1\", name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10968950375\n",
       " locality {\n",
       "   bus_id: 2\n",
       " }\n",
       " incarnation: 8802136339266664859\n",
       " physical_device_desc: \"device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:87:00.0, compute capability: 6.1\", name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 10968950375\n",
       " locality {\n",
       "   bus_id: 2\n",
       " }\n",
       " incarnation: 7429608409030987155\n",
       " physical_device_desc: \"device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:88:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.4.0\n",
      "dim_ordering: tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Activation, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_classes = 4\n",
    "batch_size = 1\n",
    "img_height, img_width = 224*5, 224*5\n",
    "input_shape = (img_height, img_width, 3)\n",
    "epochs = 50\n",
    "\n",
    "nb_train_samples = 276\n",
    "nb_validation_samples = 92\n",
    "nb_test_samples = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/processed-data/train/'\n",
    "test_dir = 'data/processed-data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 276 images belonging to 4 classes.\n",
      "Found 92 images belonging to 4 classes.\n",
      "Found 32 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "    validation_split=0.25)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    subset=\"training\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    subset=\"validation\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_weights = 'pretrained_models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "def xception_model():\n",
    "    model = Sequential()\n",
    " \n",
    "    model.add(Xception(weights = xception_weights , include_top=False,pooling = 'avg'))\n",
    "    model.add(Dense(units=output_classes, activation=tf.nn.softmax))\n",
    "    model.layers[0].trainable = True\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "         'lr': hp.choice('lr',[0.001, 0.0001, 0.00001, 0.000001]),\n",
    "#          'dropout': hp.choice('dropout', [0.4, 0.5, 0.6, 0.7]),\n",
    "#          'batch_size': hp.choice('batch_size', [64]),\n",
    "#          'epochs': hp.choice('epochs', [15, 20, 25, 30, 50]),\n",
    "#          'optimizer': hp.choice('optimizer',['sgd','adam','rmsprop']),\n",
    "#          'optimizer': hp.choice('optimizer',['rmsprop']),\n",
    "#          'optimizer': hp.choice('optimizer',['adam']),\n",
    "         'beta_1':hp.choice('beta_1',[0.3,0.4,0.5,0.6,0.7,0.8]),\n",
    "         'beta_2':hp.choice('beta_2',[0.99,0.995,0.7,0.8,0.9,0.999]),\n",
    "         'decay':hp.choice('decay',[0.0, 0.004, 0.0001, 0.1, 0.3, 0.5]),\n",
    "#          'momentum':hp.choice('momentum',[0.3,0.5,0.7,0.9,1]),\n",
    "#          'amsgrad':hp.choice('amsgrad',[False,True]),\n",
    "#          'nesterov':hp.choice('nesterov',[False,True]),\n",
    "#          'rho':hp.choice('rho',[0.4,0.5,0.6,0.7,0.8,0.9,1]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_nn(params):   \n",
    "    print ('Parameters testing: ', params)\n",
    "    model = xception_model()\n",
    "    \n",
    "    adam_opt = Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params['beta_2'], epsilon=1e-08, decay=params['decay'])\n",
    "    model.compile(optimizer = adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = nb_train_samples // batch_size,\n",
    "      epochs = 15,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps = nb_validation_samples // batch_size,\n",
    "      verbose = 1, callbacks=get_callbacks(params))\n",
    "    \n",
    "    score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "    print ('Validation Score: ', score[0])\n",
    "    print ('Validation Accuracy: ',score[1])\n",
    "    \n",
    "    filename = test_generator.filenames\n",
    "    truth = test_generator.classes\n",
    "    label = test_generator.class_indices\n",
    "    indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "    predicts = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "    predict_class = np.argmax(predicts, axis=1)\n",
    "    errors = np.where(predict_class != truth)[0]\n",
    "    print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n",
    "    \n",
    "    th= 0.3\n",
    "    acc = accuracy_score(truth, predict_class > th)\n",
    "    print(\"Test Accuracy: {:.4f}\".format(acc*100))\n",
    "    print(\"*_*\" * 50)\n",
    "\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "    return {'loss': score[0], 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(params):\n",
    "    callbacks =[EarlyStopping(monitor='val_loss', patience=3, verbose=1)]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters testing:  {'beta_1': 0.3, 'beta_2': 0.99, 'decay': 0.0, 'lr': 0.0001}\n",
      "Epoch 1/15\n",
      "276/276 [==============================] - 126s 456ms/step - loss: 1.3612 - acc: 0.3225 - val_loss: 1.5489 - val_acc: 0.2935\n",
      "Epoch 2/15\n",
      "276/276 [==============================] - 122s 443ms/step - loss: 0.9477 - acc: 0.6486 - val_loss: 3.0390 - val_acc: 0.2826\n",
      "Epoch 3/15\n",
      "276/276 [==============================] - 122s 443ms/step - loss: 0.3858 - acc: 0.9167 - val_loss: 2.8338 - val_acc: 0.3804\n",
      "Epoch 4/15\n",
      "276/276 [==============================] - 122s 442ms/step - loss: 0.0857 - acc: 0.9891 - val_loss: 2.1268 - val_acc: 0.3587\n",
      "Epoch 00004: early stopping\n",
      "Validation Score:  2.210314267963404\n",
      "Validation Accuracy:  0.4\n",
      "32/32 [==============================] - 5s 144ms/step\n",
      "No of errors = 22/32\n",
      "Test Accuracy: 25.0000\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.3, 'beta_2': 0.7, 'decay': 0.0001, 'lr': 0.0001}\n",
      "Epoch 1/15\n",
      "276/276 [==============================] - 128s 463ms/step - loss: 1.3875 - acc: 0.2717 - val_loss: 1.3869 - val_acc: 0.2500\n",
      "Epoch 2/15\n",
      "276/276 [==============================] - 123s 446ms/step - loss: 1.2896 - acc: 0.2826 - val_loss: 1.3792 - val_acc: 0.1739\n",
      "Epoch 3/15\n",
      "276/276 [==============================] - 123s 446ms/step - loss: 1.1180 - acc: 0.4819 - val_loss: 1.3034 - val_acc: 0.3152\n",
      "Epoch 4/15\n",
      "276/276 [==============================] - 123s 447ms/step - loss: 0.9059 - acc: 0.5833 - val_loss: 1.1924 - val_acc: 0.3913\n",
      "Epoch 5/15\n",
      "146/276 [==============>...............] - ETA: 52s - loss: 0.6914 - acc: 0.7877"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
