{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())\n",
    "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess = tf.Session()\n",
    "        K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7891791607675426707, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9202108990\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8570996286034513634\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "import keras.callbacks as kcall\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, ZeroPadding2D\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import Input, Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "validation_dir = 'data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train 0\n",
      "data/train\\AKIEC 3856\n",
      "data/train\\BCC 4773\n",
      "data/train\\BKL 3275\n",
      "data/train\\DF 4152\n",
      "data/train\\MEL 3308\n",
      "data/train\\NV 4975\n",
      "data/train\\VASC 3488\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(train_dir):\n",
    "    print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/validation 0\n",
      "data/validation\\AKIEC 1552\n",
      "data/validation\\BCC 1692\n",
      "data/validation\\BKL 1479\n",
      "data/validation\\DF 1632\n",
      "data/validation\\MEL 1664\n",
      "data/validation\\NV 1730\n",
      "data/validation\\VASC 1484\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(validation_dir):\n",
    "    print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27827 images belonging to 7 classes.\n",
      "Found 11233 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "\n",
    "# target_size = (height, width)\n",
    "target_size = (448, 448)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = target_size,       \n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size = target_size,        \n",
    "        class_mode = 'categorical',\n",
    "        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intilizing variables\n",
    "output_classes = 7\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "adam_opt = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, ZeroPadding2D\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "# from custom_layers import Scale\n",
    "\n",
    "def DenseNet(nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0, dropout_rate=0.4, weight_decay=1e-4, classes=7, weights_path=None):\n",
    "    '''Instantiate the DenseNet 121 architecture,\n",
    "        # Arguments\n",
    "            nb_dense_block: number of dense blocks to add to end\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_filter: initial number of filters\n",
    "            reduction: reduction factor of transition blocks.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            classes: optional number of classes to classify images\n",
    "            weights_path: path to pre-trained weights\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "\n",
    "    # compute compression factor\n",
    "    compression = 1.0 - reduction\n",
    "\n",
    "    # Handle Dimension Ordering for different backends\n",
    "    global concat_axis\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "      concat_axis = 3\n",
    "      img_input = Input(shape=(224, 224, 3), name='data')\n",
    "    else:\n",
    "      concat_axis = 1\n",
    "      img_input = Input(shape=(3, 224, 224), name='data')\n",
    "\n",
    "    # From architecture for ImageNet (Table 1 in the paper)\n",
    "    nb_filter = 64\n",
    "    nb_layers = [6,12,24,16] # For DenseNet-121\n",
    "\n",
    "    # Initial convolution\n",
    "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
    "    x = Convolution2D(nb_filter, 7, 7, subsample=(2, 2), name='conv1', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv1_scale')(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "    x = ZeroPadding2D((1, 1), name='pool1_zeropadding')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        stage = block_idx+2\n",
    "        x, nb_filter = dense_block(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "        # Add transition_block\n",
    "        x = transition_block(x, stage, nb_filter, compression=compression, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "        nb_filter = int(nb_filter * compression)\n",
    "\n",
    "    final_stage = stage + 1\n",
    "    x, nb_filter = dense_block(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv'+str(final_stage)+'_blk_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv'+str(final_stage)+'_blk_scale')(x)\n",
    "    x = Activation('relu', name='relu'+str(final_stage)+'_blk')(x)\n",
    "    x = GlobalAveragePooling2D(name='pool'+str(final_stage))(x)\n",
    "\n",
    "    x = Dense(classes, name='fc6')(x)\n",
    "    x = Activation('softmax', name='prob')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='densenet')\n",
    "\n",
    "    if weights_path is not None:\n",
    "      model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_block(x, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):\n",
    "    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout\n",
    "        # Arguments\n",
    "            x: input tensor \n",
    "            stage: index for dense block\n",
    "            branch: layer index within each dense block\n",
    "            nb_filter: number of filters\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_' + str(branch)\n",
    "    relu_name_base = 'relu' + str(stage) + '_' + str(branch)\n",
    "\n",
    "    # 1x1 Convolution (Bottleneck layer)\n",
    "    inter_channel = nb_filter * 4  \n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_x1_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base+'_x1')(x)\n",
    "    x = Convolution2D(inter_channel, 1, 1, name=conv_name_base+'_x1', bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 3x3 Convolution\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x2_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_x2_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base+'_x2')(x)\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base+'_x2_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter, 3, 3, name=conv_name_base+'_x2', bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
    "    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout \n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_filter: number of filters\n",
    "            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_blk'\n",
    "    relu_name_base = 'relu' + str(stage) + '_blk'\n",
    "    pool_name_base = 'pool' + str(stage) \n",
    "\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base)(x)\n",
    "    x = Convolution2D(int(nb_filter * compression), 1, 1, name=conv_name_base, bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2), name=pool_name_base)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_block(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True):\n",
    "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_layers: the number of layers of conv_block to append to the model.\n",
    "            nb_filter: number of filters\n",
    "            growth_rate: growth rate\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    concat_feat = x\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        branch = i+1\n",
    "        x = conv_block(concat_feat, stage, branch, growth_rate, dropout_rate, weight_decay)\n",
    "        concat_feat = merge([concat_feat, x], mode='concat', concat_axis=concat_axis, name='concat_'+str(stage)+'_'+str(branch))\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    return concat_feat, nb_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d65b5f02e105>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model = DenseNet(nb_classes=7, img_dim=448, depth=3, nb_dense_block=2, growth_rate=0.3,\n\u001b[1;32m----> 2\u001b[1;33m              nb_filter=64, dropout_rate=0.4, weight_decay=1E-4)\n\u001b[0m\u001b[0;32m      3\u001b[0m model.compile(loss='categorical_crossentropy',\n\u001b[0;32m      4\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam_opt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               metrics=['accuracy'])\n",
      "\u001b[1;32m<ipython-input-18-cdf945cdef53>\u001b[0m in \u001b[0;36mDenseNet\u001b[1;34m(nb_classes, img_dim, depth, nb_dense_block, growth_rate, nb_filter, dropout_rate, weight_decay)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \"\"\"\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mmodel_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdepth\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Depth must be 3 N + 4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[1;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[0;32m    170\u001b[0m                                    'dimension.')\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mbatch_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = DenseNet(nb_classes=7, img_dim=448, depth=3, nb_dense_block=2, growth_rate=0.3,\n",
    "             nb_filter=64, dropout_rate=0.4, weight_decay=1E-4)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam_opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras_preprocessing\\image.py:1131: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "c:\\users\\reza-lab\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras_preprocessing\\image.py:1139: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048/2048 [==============================] - 556s 271ms/step - loss: 0.9213 - acc: 0.7549 - val_loss: 1.0722 - val_acc: 0.6936\n",
      "Epoch 2/50\n",
      "2048/2048 [==============================] - 534s 261ms/step - loss: 0.5948 - acc: 0.9279 - val_loss: 0.9883 - val_acc: 0.7483\n",
      "Epoch 3/50\n",
      "2048/2048 [==============================] - 541s 264ms/step - loss: 0.4873 - acc: 0.9735 - val_loss: 0.9404 - val_acc: 0.7802\n",
      "Epoch 4/50\n",
      "2048/2048 [==============================] - 536s 262ms/step - loss: 0.4315 - acc: 0.9886 - val_loss: 0.9003 - val_acc: 0.7915\n",
      "Epoch 5/50\n",
      "2048/2048 [==============================] - 537s 262ms/step - loss: 0.3987 - acc: 0.9937 - val_loss: 0.8821 - val_acc: 0.7758\n",
      "Epoch 6/50\n",
      "2048/2048 [==============================] - 537s 262ms/step - loss: 0.3747 - acc: 0.9955 - val_loss: 0.8443 - val_acc: 0.8015\n",
      "Epoch 7/50\n",
      "2048/2048 [==============================] - 535s 261ms/step - loss: 0.3554 - acc: 0.9968 - val_loss: 0.8159 - val_acc: 0.7996\n",
      "Epoch 8/50\n",
      "2048/2048 [==============================] - 541s 264ms/step - loss: 0.3391 - acc: 0.9968 - val_loss: 0.8797 - val_acc: 0.7821\n",
      "Epoch 9/50\n",
      "2048/2048 [==============================] - 537s 262ms/step - loss: 0.3266 - acc: 0.9970 - val_loss: 0.8271 - val_acc: 0.7997\n",
      "Epoch 10/50\n",
      "2048/2048 [==============================] - 539s 263ms/step - loss: 0.3126 - acc: 0.9977 - val_loss: 0.8225 - val_acc: 0.8030\n",
      "Epoch 11/50\n",
      "2048/2048 [==============================] - 537s 262ms/step - loss: 0.3026 - acc: 0.9981 - val_loss: 0.7939 - val_acc: 0.8029\n",
      "Epoch 12/50\n",
      "2048/2048 [==============================] - 537s 262ms/step - loss: 0.2906 - acc: 0.9978 - val_loss: 0.8164 - val_acc: 0.8012\n",
      "Epoch 13/50\n",
      "2048/2048 [==============================] - 538s 263ms/step - loss: 0.2809 - acc: 0.9982 - val_loss: 0.8025 - val_acc: 0.7994\n",
      "Epoch 14/50\n",
      "2048/2048 [==============================] - 537s 262ms/step - loss: 0.2716 - acc: 0.9982 - val_loss: 0.8916 - val_acc: 0.7781\n",
      "Epoch 15/50\n",
      "2048/2048 [==============================] - 538s 263ms/step - loss: 0.2643 - acc: 0.9983 - val_loss: 0.7918 - val_acc: 0.7925\n",
      "Epoch 16/50\n",
      "2048/2048 [==============================] - 536s 262ms/step - loss: 0.2555 - acc: 0.9987 - val_loss: 0.7479 - val_acc: 0.8088\n",
      "Epoch 17/50\n",
      "2048/2048 [==============================] - 537s 262ms/step - loss: 0.2480 - acc: 0.9985 - val_loss: 0.7888 - val_acc: 0.7952\n",
      "Epoch 18/50\n",
      "2048/2048 [==============================] - 536s 262ms/step - loss: 0.2413 - acc: 0.9981 - val_loss: 0.8391 - val_acc: 0.7686\n",
      "Epoch 19/50\n",
      "1569/2048 [=====================>........] - ETA: 1:42 - loss: 0.2356 - acc: 0.9978"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "    steps_per_epoch=2048,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Test Score: ', score[0])\n",
    "print ('Test Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = validation_generator.filenames\n",
    "truth = validation_generator.classes\n",
    "label = validation_generator.class_indices\n",
    "indexlabel = dict((value, key) for key, value in label.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size, verbose=1)\n",
    "predict_class = np.argmax(predicts, axis=1)\n",
    "errors = np.where(predict_class != truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(truth,predict_class)\n",
    "\n",
    "labels = []\n",
    "for k,v in indexlabel.items():\n",
    "    labels.append(v)\n",
    "    \n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, classes=labels,\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "#and reports metrics with classification_report method\n",
    "def predict_and_report(gen, model):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    gen.reset()\n",
    "    for img, label in gen:\n",
    "        #get true labels for batch and store them\n",
    "        y_true.extend([int(z[1]) for z in label])\n",
    "        #Get predictions as probabilities\n",
    "        batch_pred = model.predict_on_batch(img)\n",
    "        #turn probabilities to class labels and store\n",
    "        batch_pred = np.argmax(batch_pred, axis=1)\n",
    "        y_pred.extend(batch_pred)\n",
    "        #break loop\n",
    "        if gen.batch_index == 0:\n",
    "            break\n",
    "            \n",
    "    print('Accuracy:', accuracy_score(y_true, y_pred))\n",
    "    print('Area Under the Receiver Operating Characteristic Curve:', roc_auc_score(y_true, y_pred)) #Area under the curve\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_report(train_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_report(validation_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/2.Alex-Dropout-Model.h5')\n",
    "model.save_weights('models/2.Alex-Dropout-Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_factory(x, nb_filter, dropout_rate=None, weight_decay=1E-4):\n",
    "    \"\"\"Apply BatchNorm, Relu 3x3Conv2D, optional dropout\n",
    "    :param x: Input keras network\n",
    "    :param nb_filter: int -- number of filters\n",
    "    :param dropout_rate: int -- dropout rate\n",
    "    :param weight_decay: int -- weight decay factor\n",
    "    :returns: keras network with b_norm, relu and Conv2D added\n",
    "    :rtype: keras network\n",
    "    \"\"\"\n",
    "\n",
    "    x = BatchNormalization(axis=1,\n",
    "                           gamma_regularizer=l2(weight_decay),\n",
    "                           beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_filter, (3, 3),\n",
    "               kernel_initializer=\"he_uniform\",\n",
    "               padding=\"same\",\n",
    "               use_bias=False,\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition(x, nb_filter, dropout_rate=None, weight_decay=1E-4):\n",
    "    \"\"\"Apply BatchNorm, Relu 1x1Conv2D, optional dropout and Maxpooling2D\n",
    "    :param x: keras model\n",
    "    :param nb_filter: int -- number of filters\n",
    "    :param dropout_rate: int -- dropout rate\n",
    "    :param weight_decay: int -- weight decay factor\n",
    "    :returns: model\n",
    "    :rtype: keras model, after applying batch_norm, relu-conv, dropout, maxpool\n",
    "    \"\"\"\n",
    "\n",
    "    x = BatchNormalization(axis=1,\n",
    "                           gamma_regularizer=l2(weight_decay),\n",
    "                           beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_filter, (1, 1),\n",
    "               kernel_initializer=\"he_uniform\",\n",
    "               padding=\"same\",\n",
    "               use_bias=False,\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def denseblock(x, nb_layers, nb_filter, growth_rate,\n",
    "               dropout_rate=None, weight_decay=1E-4):\n",
    "    \"\"\"Build a denseblock where the output of each\n",
    "       conv_factory is fed to subsequent ones\n",
    "    :param x: keras model\n",
    "    :param nb_layers: int -- the number of layers of conv_\n",
    "                      factory to append to the model.\n",
    "    :param nb_filter: int -- number of filters\n",
    "    :param dropout_rate: int -- dropout rate\n",
    "    :param weight_decay: int -- weight decay factor\n",
    "    :returns: keras model with nb_layers of conv_factory appended\n",
    "    :rtype: keras model\n",
    "    \"\"\"\n",
    "\n",
    "    list_feat = [x]\n",
    "\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        concat_axis = 1\n",
    "    elif K.image_dim_ordering() == \"tf\":\n",
    "        concat_axis = -1\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        x = conv_factory(x, growth_rate, dropout_rate, weight_decay)\n",
    "        list_feat.append(x)\n",
    "        x = Concatenate(axis=concat_axis)(list_feat)\n",
    "        nb_filter += growth_rate\n",
    "\n",
    "    return x, nb_filter\n",
    "\n",
    "\n",
    "def denseblock_altern(x, nb_layers, nb_filter, growth_rate,\n",
    "                      dropout_rate=None, weight_decay=1E-4):\n",
    "    \"\"\"Build a denseblock where the output of each conv_factory\n",
    "       is fed to subsequent ones. (Alternative of a above)\n",
    "    :param x: keras model\n",
    "    :param nb_layers: int -- the number of layers of conv_\n",
    "                      factory to append to the model.\n",
    "    :param nb_filter: int -- number of filters\n",
    "    :param dropout_rate: int -- dropout rate\n",
    "    :param weight_decay: int -- weight decay factor\n",
    "    :returns: keras model with nb_layers of conv_factory appended\n",
    "    :rtype: keras model\n",
    "    * The main difference between this implementation and the implementation\n",
    "    above is that the one above\n",
    "    \"\"\"\n",
    "\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        concat_axis = 1\n",
    "    elif K.image_dim_ordering() == \"tf\":\n",
    "        concat_axis = -1\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        merge_tensor = conv_factory(x, growth_rate, dropout_rate, weight_decay)\n",
    "        x = Concatenate(axis=concat_axis)([merge_tensor, x])\n",
    "        nb_filter += growth_rate\n",
    "\n",
    "    return x, nb_filter\n",
    "\n",
    "\n",
    "def DenseNet(nb_classes, img_dim, depth, nb_dense_block, growth_rate,\n",
    "             nb_filter, dropout_rate=None, weight_decay=1E-4):\n",
    "    \"\"\" Build the DenseNet model\n",
    "    :param nb_classes: int -- number of classes\n",
    "    :param img_dim: tuple -- (channels, rows, columns)\n",
    "    :param depth: int -- how many layers\n",
    "    :param nb_dense_block: int -- number of dense blocks to add to end\n",
    "    :param growth_rate: int -- number of filters to add\n",
    "    :param nb_filter: int -- number of filters\n",
    "    :param dropout_rate: float -- dropout rate\n",
    "    :param weight_decay: float -- weight decay\n",
    "    :returns: keras model with nb_layers of conv_factory appended\n",
    "    :rtype: keras model\n",
    "    \"\"\"\n",
    "\n",
    "    model_input = Input(shape=img_dim)\n",
    "\n",
    "    assert (depth - 4) % 3 == 0, \"Depth must be 3 N + 4\"\n",
    "\n",
    "    # layers in each dense block\n",
    "    nb_layers = int((depth - 4) / 3)\n",
    "\n",
    "    # Initial convolution\n",
    "    x = Conv2D(nb_filter, (3, 3),\n",
    "               kernel_initializer=\"he_uniform\",\n",
    "               padding=\"same\",\n",
    "               name=\"initial_conv2D\",\n",
    "               use_bias=False,\n",
    "               kernel_regularizer=l2(weight_decay))(model_input)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        x, nb_filter = denseblock(x, nb_layers, nb_filter, growth_rate,\n",
    "                                  dropout_rate=dropout_rate,\n",
    "                                  weight_decay=weight_decay)\n",
    "        # add transition\n",
    "        x = transition(x, nb_filter, dropout_rate=dropout_rate,\n",
    "                       weight_decay=weight_decay)\n",
    "\n",
    "    # The last denseblock does not have a transition\n",
    "    x, nb_filter = denseblock(x, nb_layers, nb_filter, growth_rate,\n",
    "                              dropout_rate=dropout_rate,\n",
    "                              weight_decay=weight_decay)\n",
    "\n",
    "    x = BatchNormalization(axis=1,\n",
    "                           gamma_regularizer=l2(weight_decay),\n",
    "                           beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D(data_format=K.image_data_format())(x)\n",
    "    x = Dense(nb_classes,\n",
    "              activation='softmax',\n",
    "              kernel_regularizer=l2(weight_decay),\n",
    "              bias_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "    densenet = Model(inputs=[model_input], outputs=[x], name=\"DenseNet\")\n",
    "\n",
    "    return densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
